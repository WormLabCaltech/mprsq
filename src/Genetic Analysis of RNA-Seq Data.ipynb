{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Genetic-Analysis-of-a-Metazoan-Pathway-using-Transcriptomic-Phenotypes-Supplementary-and-Extended-Material\" data-toc-modified-id=\"Genetic-Analysis-of-a-Metazoan-Pathway-using-Transcriptomic-Phenotypes-Supplementary-and-Extended-Material-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Genetic Analysis of a Metazoan Pathway using Transcriptomic Phenotypes Supplementary and Extended Material</a></div><div class=\"lev1 toc-item\"><a href=\"#Folder-Structure\" data-toc-modified-id=\"Folder-Structure-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Folder Structure</a></div><div class=\"lev1 toc-item\"><a href=\"#Read-alignment-and-differential-expression-analysis\" data-toc-modified-id=\"Read-alignment-and-differential-expression-analysis-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Read alignment and differential expression analysis</a></div><div class=\"lev1 toc-item\"><a href=\"#Introduction:-Genetic-Analysis-Using-Global-Expression-Measurements\" data-toc-modified-id=\"Introduction:-Genetic-Analysis-Using-Global-Expression-Measurements-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Introduction: Genetic Analysis Using Global Expression Measurements</a></div><div class=\"lev2 toc-item\"><a href=\"#PCA-Analysis-of-TPM-Data\" data-toc-modified-id=\"PCA-Analysis-of-TPM-Data-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>PCA Analysis of TPM Data</a></div><div class=\"lev1 toc-item\"><a href=\"#Figure-1.-Dendrogram-Clustering\" data-toc-modified-id=\"Figure-1.-Dendrogram-Clustering-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Figure 1. Dendrogram Clustering</a></div><div class=\"lev2 toc-item\"><a href=\"#Filtering-Does-Not-Seriously-Alter-Differentially-Expressed-Genes\" data-toc-modified-id=\"Filtering-Does-Not-Seriously-Alter-Differentially-Expressed-Genes-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Filtering Does Not Seriously Alter Differentially Expressed Genes</a></div><div class=\"lev1 toc-item\"><a href=\"#Bayesian-versus-Spearman-Regressions\" data-toc-modified-id=\"Bayesian-versus-Spearman-Regressions-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Bayesian versus Spearman Regressions</a></div><div class=\"lev2 toc-item\"><a href=\"#Spearman-Regression-Method\" data-toc-modified-id=\"Spearman-Regression-Method-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Spearman Regression Method</a></div><div class=\"lev2 toc-item\"><a href=\"#Bayesian-Robust-Regression\" data-toc-modified-id=\"Bayesian-Robust-Regression-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Bayesian Robust Regression</a></div><div class=\"lev2 toc-item\"><a href=\"#Figure-4.-Complex-Regulation-Generates-Detectable-Patterns-in-Transcriptomes\" data-toc-modified-id=\"Figure-4.-Complex-Regulation-Generates-Detectable-Patterns-in-Transcriptomes-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Figure 4. Complex Regulation Generates Detectable Patterns in Transcriptomes</a></div><div class=\"lev2 toc-item\"><a href=\"#Figure-2.-Positive-Regulatory-Relationships-Can-Be-Identified-By-Transcriptomic-Correlation\" data-toc-modified-id=\"Figure-2.-Positive-Regulatory-Relationships-Can-Be-Identified-By-Transcriptomic-Correlation-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Figure 2. Positive Regulatory Relationships Can Be Identified By Transcriptomic Correlation</a></div><div class=\"lev1 toc-item\"><a href=\"#Pairwise-Analysis-of-All-Genes-Using-Spearman-Correlation\" data-toc-modified-id=\"Pairwise-Analysis-of-All-Genes-Using-Spearman-Correlation-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Pairwise Analysis of All Genes Using Spearman Correlation</a></div><div class=\"lev1 toc-item\"><a href=\"#Hypergeometric-Analysis:\" data-toc-modified-id=\"Hypergeometric-Analysis:-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Hypergeometric Analysis:</a></div><div class=\"lev1 toc-item\"><a href=\"#Analysis-Using-Robust-Regression\" data-toc-modified-id=\"Analysis-Using-Robust-Regression-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Analysis Using Robust Regression</a></div><div class=\"lev2 toc-item\"><a href=\"#Figure-3.-Pairwise-regression-values-between-all-single-mutants\" data-toc-modified-id=\"Figure-3.-Pairwise-regression-values-between-all-single-mutants-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Figure 3. Pairwise regression values between all single mutants</a></div><div class=\"lev1 toc-item\"><a href=\"#Extracting-functional-relationships-between-genes\" data-toc-modified-id=\"Extracting-functional-relationships-between-genes-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Extracting functional relationships between genes</a></div><div class=\"lev2 toc-item\"><a href=\"#Figure-4.-Weighted-Correlations-Reflect-Functional-Distance\" data-toc-modified-id=\"Figure-4.-Weighted-Correlations-Reflect-Functional-Distance-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Figure 4. Weighted Correlations Reflect Functional Distance</a></div><div class=\"lev1 toc-item\"><a href=\"#Double-Mutant-Analysis\" data-toc-modified-id=\"Double-Mutant-Analysis-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Double Mutant Analysis</a></div><div class=\"lev1 toc-item\"><a href=\"#Defining-the-Hypoxia-Response\" data-toc-modified-id=\"Defining-the-Hypoxia-Response-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Defining the Hypoxia Response</a></div><div class=\"lev1 toc-item\"><a href=\"#The-genes-upregulated-by-egl-9-should-be-down-in-hif-1.\" data-toc-modified-id=\"The-genes-upregulated-by-egl-9-should-be-down-in-hif-1.-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>The genes upregulated by <em>egl-9</em> should be down in <em>hif-1</em>.</a></div><div class=\"lev1 toc-item\"><a href=\"#Quality-Control\" data-toc-modified-id=\"Quality-Control-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Quality Control</a></div><div class=\"lev1 toc-item\"><a href=\"#Correlation-Graph\" data-toc-modified-id=\"Correlation-Graph-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Correlation Graph</a></div><div class=\"lev1 toc-item\"><a href=\"#An-in-silico-qPCR-experiment:\" data-toc-modified-id=\"An-in-silico-qPCR-experiment:-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>An <em>in silico</em> qPCR experiment:</a></div><div class=\"lev1 toc-item\"><a href=\"#Define-the-Absolute-Gold-Set\" data-toc-modified-id=\"Define-the-Absolute-Gold-Set-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>Define the Absolute Gold Set</a></div><div class=\"lev1 toc-item\"><a href=\"#Hypoxia-Positive-Interaction\" data-toc-modified-id=\"Hypoxia-Positive-Interaction-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>Hypoxia Positive Interaction</a></div><div class=\"lev1 toc-item\"><a href=\"#Searching-for-a-TF-that-is-activated-by-both-egl-9-and-hif-1\" data-toc-modified-id=\"Searching-for-a-TF-that-is-activated-by-both-egl-9-and-hif-1-19\"><span class=\"toc-item-num\">19&nbsp;&nbsp;</span>Searching for a TF that is activated by both egl-9 and hif-1</a></div><div class=\"lev1 toc-item\"><a href=\"#Finding-direct-targets-of-hif-1,-vhl-1,-egl-9-and-rhy-1\" data-toc-modified-id=\"Finding-direct-targets-of-hif-1,-vhl-1,-egl-9-and-rhy-1-20\"><span class=\"toc-item-num\">20&nbsp;&nbsp;</span>Finding direct targets of <em>hif-1</em>, <em>vhl-1</em>, <em>egl-9</em> and <em>rhy-1</em></a></div><div class=\"lev2 toc-item\"><a href=\"#hif-1-direct-targets\" data-toc-modified-id=\"hif-1-direct-targets-20.1\"><span class=\"toc-item-num\">20.1&nbsp;&nbsp;</span><em>hif-1</em> direct targets</a></div><div class=\"lev2 toc-item\"><a href=\"#Quality-control-on-identified-genes:\" data-toc-modified-id=\"Quality-control-on-identified-genes:-20.2\"><span class=\"toc-item-num\">20.2&nbsp;&nbsp;</span>Quality control on identified genes:</a></div><div class=\"lev2 toc-item\"><a href=\"#Identifying-rhy-1-targets\" data-toc-modified-id=\"Identifying-rhy-1-targets-20.3\"><span class=\"toc-item-num\">20.3&nbsp;&nbsp;</span>Identifying <em>rhy-1</em> targets</a></div><div class=\"lev2 toc-item\"><a href=\"#Identifying-egl-9-targets\" data-toc-modified-id=\"Identifying-egl-9-targets-20.4\"><span class=\"toc-item-num\">20.4&nbsp;&nbsp;</span>Identifying <em>egl-9</em> targets</a></div><div class=\"lev2 toc-item\"><a href=\"#Identifying-vhl-1-targets\" data-toc-modified-id=\"Identifying-vhl-1-targets-20.5\"><span class=\"toc-item-num\">20.5&nbsp;&nbsp;</span>Identifying <em>vhl-1</em> targets</a></div><div class=\"lev2 toc-item\"><a href=\"#Identifying-New-Biology---understanding-the-role-of-rhy-1-and-egl-9-in-the-hif-1-dependent-response\" data-toc-modified-id=\"Identifying-New-Biology---understanding-the-role-of-rhy-1-and-egl-9-in-the-hif-1-dependent-response-20.6\"><span class=\"toc-item-num\">20.6&nbsp;&nbsp;</span>Identifying New Biology - understanding the role of <em>rhy-1</em> and <em>egl-9</em> in the <em>hif-1</em> dependent response</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Analysis of a Metazoan Pathway using Transcriptomic Phenotypes Supplementary and Extended Material\n",
    "**David Angeles-Albores, Carmie Puckett Robinson, Brian Williams, Igot Antoshechkin, and Paul W Sternberg**\n",
    "\n",
    "The purpose of this notebook is to serve as an extended, interactive document for our [paper](http://www.wormbase.org/).\n",
    "\n",
    "All code in this notebook was written, documented and generated by David Angeles-Albores. In cases when code was inspired, written or shown elsewhere first, links have been provided to the source material where possible.\n",
    "\n",
    "100% of the data, with the exception of the raw reads, is deposited in our [GitHub project](https://github.com/WormLabCaltech/mprsq). If you would like to verify our analysis, you are welcome to fork the project, although we will not allow pulls into the main branches. I hope you find this useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder Structure\n",
    "\n",
    "The folder structure is a little bit important if you want to replicate the findings presented here. \n",
    "\n",
    "Briefly, the folder structure is contained in the following major folders:\n",
    "\n",
    " * input - contains raw FASTQ files, kallisto_all (processed reads), genmap file, TF list, cDNA file, transcripts.idx, enrichment dictionaries and hypoxia gold standard gene files\n",
    " * sleuth - contains differential analysis (no *fog-2* included) results\n",
    " * sleuth_batch_adjusted - contains differential analysis results with *fog-2* included\n",
    " * src - all python scripts\n",
    " * output - all figures\n",
    " * tex - manuscript\n",
    " * experimental_docs - all bioanalyzer results are placed here\n",
    "\n",
    "# Read alignment and differential expression analysis\n",
    "\n",
    " The raw FASTQ reads are in input/rawseq/PROJECT_NAME/. These reads are processed by running **kallisto_bash_generator.py**, then from terminal (in the main directory) *chmod +x kallisto commands.sh; sh kallisto_commands.sh*. Reads were processed using a length of **180**bp, with a standard deviation of **60** basepairs, bootstrapped 200 times. The results from this analysis are then placed in input/kallisto_all/PROJECT_NAME/.\n",
    " \n",
    " Sleuth analysis was performed by running **Sleuth_Prep.py**, then **Sleuth_Command_Writer.py** which generates the folder *sleuth/*. After writing the **diff_exp_analyzer.R** and placing it within the sleuth folder, navigate to sleuth folder using terminal, then type *chmod +x sleuth_commands.sh*, then *sh sleut_commands.sh*. This will perform the differential expression analysis. The results are stored in folders named WT_X, where X is the genotype being compared to wild-type. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Genetic Analysis Using Global Expression Measurements\n",
    "\n",
    "The following sections will provide (excruciating) detail on how we performed the genetic analysis of our mutants using this data. Initially, this analysis was done blindly. For clarity, I have added all the genotype identifiers from the beginning.\n",
    "\n",
    "To start, we should load all the python libraries that we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"6f7f854e-cf66-43d3-9e58-be5a362a76e2\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = \"1\";\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force !== \"\") {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      Bokeh.$(\"#6f7f854e-cf66-43d3-9e58-be5a362a76e2\").text(\"BokehJS successfully loaded.\");\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"6f7f854e-cf66-43d3-9e58-be5a362a76e2\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '6f7f854e-cf66-43d3-9e58-be5a362a76e2' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.12.2.min.js'];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      Bokeh.$(\"#6f7f854e-cf66-43d3-9e58-be5a362a76e2\").text(\"BokehJS is loading...\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.2.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.2.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === \"1\")) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === \"1\") {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (!force) {\n",
       "      var cell = $(\"#6f7f854e-cf66-43d3-9e58-be5a362a76e2\").parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# important stuff:\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# stats\n",
    "import sklearn.decomposition\n",
    "from scipy import stats as sts\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "# TEA and morgan\n",
    "import tissue_enrichment_analysis as tea\n",
    "import morgan as morgan\n",
    "\n",
    "# network graphics\n",
    "import networkx as nx\n",
    "\n",
    "# Graphics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as plticker\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patheffects as path_effects\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "\n",
    "# bokeh\n",
    "import bokeh.charts\n",
    "import bokeh.charts.utils\n",
    "import bokeh.io\n",
    "import bokeh.models\n",
    "import bokeh.palettes\n",
    "import bokeh.plotting\n",
    "\n",
    "# bayes and mcmc\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "\n",
    "# Display graphics in this notebook\n",
    "bokeh.io.output_notebook()\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables SVG graphics inline.  There is a bug, so uncomment if it works.\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# JB's favorite Seaborn settings for notebooks\n",
    "rc = {'lines.linewidth': 2, \n",
    "      'axes.labelsize': 18, \n",
    "      'axes.titlesize': 18, \n",
    "      'axes.facecolor': 'DFDFE5'}\n",
    "sns.set_context('notebook', rc=rc)\n",
    "sns.set_style(\"dark\")\n",
    "\n",
    "ft = 35 #title fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I need to load the **phenotype_df** (please don't use this file without permission for publication purposes. This tool is unpublished [I am actively working on a paper with this] and will be available soon. I provide it here for clarity, even though it was not part of our paper), the **tissue_df** and the **tf_df**. These files contains a phenotype-gene dictionary, a tissue-gene dictionary (downloaded from TEA) and a transcription factor list (from Chris Grove). \n",
    "\n",
    "Additionally, I will initialize several variables whose purpose will mainly be to prettify the tables and substitute in the correct names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phenotype_df = pd.read_csv('../input/dictionaries/phenotype_dictionary.csv')\n",
    "tissue_df = tea.fetch_dictionary()\n",
    "tf_df = pd.read_csv('../input/tf_list.csv')\n",
    "hypoxia_gold = pd.read_csv('../input/hypoxia_gold_standard.csv', sep=',')\n",
    "\n",
    "genotype_mapping = {'a': r'\\emph{egl-9;vhl-1}',\n",
    "                    'f': r'\\emph{egl-9;hif-1}',\n",
    "                    'b': r'\\emph{egl-9}',\n",
    "                    'c': r'\\emph{hif-1}',\n",
    "                    'd': r'\\emph{vhl-1}',\n",
    "                    'e': r'\\emph{rhy-1}',\n",
    "                    'g': r'\\emph{fog-2}'\n",
    "                    }\n",
    "\n",
    "sort_pairs = {'eb': 1, 'be': 1,\n",
    "              'ed': 2,'de': 2,\n",
    "              'ec': 3,'ce': 3,\n",
    "              'eg': 4,'ge': 4,\n",
    "              'bd': 5,'db': 5,\n",
    "              'cb': 6,'bc': 6,\n",
    "              'bg': 7, 'gb': 7,\n",
    "              'cd': 8,'dc': 8,\n",
    "              'dg': 9,'gd': 9,\n",
    "              'cg': 10,'gc': 10\n",
    "             }\n",
    "\n",
    "decode_pairs = {'eb': '\\emph{rhy-1}, \\emph{egl-9}', 'be': '\\emph{rhy-1}, \\emph{egl-9}',\n",
    "              'ed': '\\emph{rhy-1}, \\emph{vhl-1}','de': '\\emph{rhy-1}, \\emph{vhl-1}',\n",
    "              'ec': '\\emph{rhy-1}, \\emph{hif-1}','ce': '\\emph{rhy-1}, \\emph{hif-1}',\n",
    "              'eg': '\\emph{rhy-1}, \\emph{fog-2}','ge': '\\emph{rhy-1}, \\emph{fog-2}',\n",
    "              'bd': '\\emph{egl-9}, \\emph{vhl-1}','db': '\\emph{egl-9}, \\emph{vhl-1}',\n",
    "              'cb': '\\emph{egl-9}, \\emph{hif-1}','bc': '\\emph{egl-9}, \\emph{hif-1}',\n",
    "              'bg': '\\emph{egl-9}, \\emph{fog-2}', 'gb': '\\emph{egl-9}, \\emph{fog-2}',\n",
    "              'cd': '\\emph{vhl-1}, \\emph{hif-1}','dc': '\\emph{vhl-1}, \\emph{hif-1}',\n",
    "              'dg': '\\emph{hif-1}, \\emph{fog-2}','gd': '\\emph{vhl-1}, \\emph{fog-2}',\n",
    "              'cg': '\\emph{hif-1}, \\emph{fog-2}','gc': '\\emph{hif-1}, \\emph{fog-2}'\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load up all of our files. These files will be placed within a class called morgan.hunt (funny!). All of the classes that are referenced in this tutorial are in the file morgan.py, which you are welcome to use for your own analysis. The classes are relatively well-documented and should be usable if you are careful. That said, I am not a computer scientist, so some pathologies or bugs may pop up -- if they do, please perform a pull-request on our github with a fix for the bug. Alternatively, please email me a sufficiently detailed script so I can reconstruct the failure event and correct the bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Specify the genotypes to refer to:\n",
    "single_mutants = ['b', 'c', 'd', 'e']\n",
    "# Specify which genotypes are double mutants and of what single mutants:\n",
    "double_mutants = {'a' : 'bd', 'f':'bc'}\n",
    "\n",
    "# initialize the morgan.hunt object:\n",
    "# target_id is the column with isoform specific names\n",
    "# b is the name of the column with the GLM regression coefficients\n",
    "# tpm is the name of the column with the TPM numbers\n",
    "# qval is the name of the column with the FDR corrected q-values\n",
    "thomas = morgan.hunt('target_id', 'b', 'tpm', 'qval')\n",
    "\n",
    "# input the genmap file:\n",
    "thomas.add_genmap('../input/library_genotype_mapping.txt', comment='#')\n",
    "\n",
    "# add the names of the single mutants\n",
    "thomas.add_single_mutant(single_mutants)\n",
    "\n",
    "# add the names of the double mutants\n",
    "thomas.add_double_mutants(['a', 'f'], ['bd', 'bc'])\n",
    "\n",
    "# set the q-value threshold for significance to its default value, 0.1\n",
    "thomas.set_qval()\n",
    "\n",
    "# Add the tpm files: \n",
    "kallisto_loc = '../input/kallisto_all/'\n",
    "thomas.add_tpm(kallisto_loc, '/kallisto/abundance.tsv', '')\n",
    "\n",
    "# Make all possible combinations of WT, X\n",
    "combs = {}\n",
    "for gene in thomas.genmap.genotype.unique():\n",
    "    if gene != 'wt':\n",
    "        combs[gene] = 'WT_'+gene+'/'\n",
    "\n",
    "# load all the beta values for each genotype:\n",
    "sleuth_loc = '../sleuth/'\n",
    "thomas.add_betas(sleuth_loc, 'betas.csv', combs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will filter the data, removing any genes that don't show up in all the files and removing the bottom 10% of the genes by expression level. This is an aggressive cutoff, I know. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of na genes: 983\n"
     ]
    }
   ],
   "source": [
    "thomas.filter_data(0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Analysis of TPM Data\n",
    "\n",
    "PCA analysis of TPM data should hopefully reveal some structure and clustering in this dataset and show us that this isn't pointless immediately. \n",
    "\n",
    "First, I want to know how many PCs explain >90% of the data, then build a PCA object with that\n",
    "many dimensions which I will use for agglomerative clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PCA\n",
    "#exclude g\n",
    "pca_matrix = genpy.make_matrix(thomas.tpm, thomas.genmap, 'project_name', 'tpm')\n",
    "sklearn_pca, n = genpy.pca(pca_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep only the first principal components that explain 90% of the data\n",
    "if n < 3:\n",
    "    n = 3\n",
    "\n",
    "df_nD = genpy.tidy_pca(pca_matrix, n)\n",
    "\n",
    "# add a sample and genotype column\n",
    "df_nD['samples'] = thomas.genmap.project_name.unique()\n",
    "l = lambda x: thomas.genmap[thomas.genmap.project_name == x].genotype.values[0]\n",
    "df_nD['genotypes'] = df_nD.samples.apply(l)\n",
    "df_nD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_2d_pca(df_pca, group_col, special_key, double_mutant_hash= {},save=''):\n",
    "    \"\"\"\n",
    "    Very basic wrapper around plt.plot to plot pca results after using tidy_pca.\n",
    "    \n",
    "    df_pca - df output by tidy_pca\n",
    "    group_col - column in df_pca to group by\n",
    "    special_key - if there's a particular group to color in black, use special_key\n",
    "                  to identify it\n",
    "    \n",
    "    returns:\n",
    "    a matplotlib object\n",
    "    \"\"\"\n",
    "    # plot first 2d components! \n",
    "    for key, group in df_nD.groupby(group_col):\n",
    "        if key in genotype_mapping.keys():\n",
    "            lab = genotype_mapping[key]\n",
    "        else:\n",
    "            lab = key\n",
    "        if key == special_key:\n",
    "            plt.plot(group.PCA1, group.PCA2, 'ko', alpha=0.9, label=lab, ms=17)\n",
    "        else:\n",
    "            if key not in double_mutant_hash.keys():\n",
    "                plt.plot(group.PCA1, group.PCA2, 'o', alpha=.9, label=lab, ms=17)\n",
    "            else:\n",
    "                plt.plot(group.PCA1, group.PCA2, 'o', alpha=.9, label=lab, ms=17)\n",
    "\n",
    "    # Tidy up plot\n",
    "    plt.legend(bbox_to_anchor=(1.2, 1), fontsize=20).set_path_effects([path_effects.Normal()])\n",
    "    plt.margins(0.05)\n",
    "    plt.xlabel('PCA 1').set_path_effects([path_effects.Normal()])\n",
    "    plt.ylabel('PCA 2').set_path_effects([path_effects.Normal()])\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "    \n",
    "    \n",
    "plot_2d_pca(df_nD, 'genotypes', 'wt', double_mutants)\n",
    "plt.legend(loc=(1.05, 0.5))\n",
    "\n",
    "ax = plt.gca()\n",
    "for i, label in enumerate(ax.get_xticklabels()[::1]):\n",
    "    ax.get_xticklabels()[::1][i] = ax.get_xticklabels()[::1][i].set_path_effects([path_effects.Normal()])\n",
    "loc = plticker.MultipleLocator(base=10**4) # this locator puts ticks at regular intervals\n",
    "ax.xaxis.set_major_locator(loc)\n",
    "loc = plticker.MultipleLocator(base=5*10**3) # this locator puts ticks at regular intervals\n",
    "ax.yaxis.set_major_locator(loc)\n",
    "plt.title('RNA-Seq is a Tool for\\nMeasuring Complex Phenotypes', fontsize=ft).set_path_effects([path_effects.Normal()])\n",
    "plt.savefig('../output/tpm_pca.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, we can see a few things:\n",
    "\n",
    "*egl-9*, *vhl-1* and *rhy-1* all cluster far away from the WT, primarily along PCA1. \n",
    "\n",
    "The double mutant *egl-9; vhl-1* has a mean PCA location very close to *egl-9*. \n",
    "\n",
    "The mutant *hif-1* has a centroid relatively close to the WT. \n",
    "\n",
    "The double mutant *hif-1* is almost identical to the WT.\n",
    "\n",
    "However, we are only looking at the first 2 dimensions of the PCA, and we know that 90% of the variance is contained in the first 4. So we can perform agglomerative clustering to make sure these observations are correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1. Dendrogram Clustering\n",
    "\n",
    "Having performed the above analysis, let's go ahead and make the (almost finished) dendrogram figure in the paper. The only post-processing this will undergo is manually changing the letters to gene names and removing some of the labels for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform agglomerative clustering\n",
    "model = hierarchy.linkage(sklearn_pca.transform(pca_matrix), 'ward')\n",
    "\n",
    "# Draw a canvas:\n",
    "plt.figure(figsize=(25, 10))\n",
    "\n",
    "# extract the labels:\n",
    "labels = df_nD.genotypes.values\n",
    "\n",
    "# rename the double mutant labels (i.e. instead of 'a' --> 'bd')\n",
    "for i, label in enumerate(labels):\n",
    "    if label in double_mutants:\n",
    "        labels[i] = double_mutants[label]\n",
    "\n",
    "# Linewidth parameter, temporarily set to 7\n",
    "plt.rcParams['lines.linewidth'] = 7\n",
    "\n",
    "# set colors (black; blue)\n",
    "hierarchy.set_link_color_palette(['k', 'b'])\n",
    "\n",
    "# draw the dendrogram\n",
    "hierarchy.dendrogram(\n",
    "    model,\n",
    "    truncate_mode='level',  # show only the last p merged clusters\n",
    "    labels=df_nD.genotypes.values,\n",
    "    p=21,  # show only the last p merged clusters\n",
    "    show_leaf_counts=False,  # otherwise numbers in brackets are counts\n",
    "    leaf_rotation=90.,\n",
    "    leaf_font_size=12.,\n",
    "    show_contracted=True,  # to get a distribution impression in truncated branches\n",
    "    above_threshold_color='k'\n",
    ")\n",
    "\n",
    "# get the current axis\n",
    "ax = plt.gca()\n",
    "\n",
    "# add in the orange and green boxes\n",
    "height = ax.get_ylim()[1]*.36\n",
    "ax.fill_between([90, 210], 0.0, height, \n",
    "                    where=[1,1], color='g', alpha=0.55, zorder=0)\n",
    "ax.fill_between([0, 90], 0.0, height*1.3, \n",
    "                    where=[1,1], color='#e66101', alpha=1, zorder=0)\n",
    "\n",
    "plt.xticks(fontsize=55)\n",
    "plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "plt.title('Clustering by Expression Recapitulates Epistatic Interactions', fontsize=ft*1.5)\n",
    "plt.savefig('../output/tpm_dendrogram.pdf', bbox_inches='tight')\n",
    "\n",
    "# return linewidth to a reasonable setting\n",
    "plt.rcParams['lines.linewidth'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, it does appear that *hif-1* is closest to the WT out of all the genes in this study. Moreover, please do notice that we can get epistasis relationships out of this data. Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Does Not Seriously Alter Differentially Expressed Genes\n",
    "\n",
    "In the section above, I filtered somewhat aggressively. Let's verify that there's not too much change in the number of genes that we detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# go through each dataset\n",
    "for key, df in thomas.beta.items():\n",
    "    # before filtering:\n",
    "    # find the significantly altered genes in each mutant\n",
    "    sig_genes = len(df[df.qval < thomas.q])\n",
    "    # calculate the mean fold change (technically a biased estimator of the fold change)\n",
    "    # as e^(b_mean)\n",
    "    mc = np.exp(df[df.qval < thomas.q].b.abs().max())\n",
    "    \n",
    "    # print the result\n",
    "    print('{0} has {1} diff. exp. genes before\\\n",
    " filtering with mean fold change {2:.2g}'.format(key, sig_genes, mc))\n",
    "    # after filtering:\n",
    "    df = thomas.beta_filtered[key]\n",
    "    sig_genes = len(df[df.qval < q])\n",
    "    print('{0} has {1} diff. exp. genes after filtering'.format(key, sig_genes))\n",
    "    print('-----------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian versus Spearman Regressions\n",
    "\n",
    "Ok! Having verified that we still have plenty of power to identify these mutants, we need to go ahead and perform some statistics. Next, I will define some useful functions to make plotting easier. After that, I will begin a detailed analysis of the different prediction methods, specifically attempting to compare Spearman rank regression with a Bayesian linear regression of ranked data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pathify(title, xlabel, ylabel, xticks=True, yticks=True, **kwargs):\n",
    "    \"\"\"\n",
    "    A function to pathify the labels, titles and ticks in a plot.\n",
    "    \"\"\"\n",
    "    labelsize = kwargs.pop('labelsize', 20)\n",
    "    titlesize = kwargs.pop('titlesize', 25)\n",
    "    \n",
    "    # make the labels and title into paths\n",
    "    plt.ylabel(ylabel, fontsize=labelsize).set_path_effects([path_effects.Normal()])\n",
    "    plt.xlabel(xlabel, fontsize=labelsize).set_path_effects([path_effects.Normal()])\n",
    "    plt.title(title, fontsize=titlesize).set_path_effects([path_effects.Normal()])\n",
    "\n",
    "    ax = plt.gca()\n",
    "    # go through each xtick or ytick and make it a path if user specified to do so.\n",
    "    if xticks == True:\n",
    "        for i, label in enumerate(ax.get_xticklabels()):\n",
    "            ax.get_xticklabels()[i].set_path_effects([path_effects.Normal()])\n",
    "    if yticks == True:\n",
    "        for i, label in enumerate(ax.get_yticklabels()):\n",
    "            ax.get_yticklabels()[i].set_path_effects([path_effects.Normal()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spearman Regression Method\n",
    "\n",
    "In order to perform the Spearman regression, this is what I will do:\n",
    "\n",
    " * Extract the pertinent datasets for the two genotypes I want to convert.\n",
    " * Find the genes that are altered between both conditions, regardless of direction\n",
    " * After finding this overlap, rank the genes by their $\\beta$ coefficient in each dataset\n",
    " * Perform Least Squares on the ranked data, which is the Spearman Regression\n",
    " * Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lambda index function:\n",
    "lind = lambda x: (x.qval < 0.1)\n",
    "\n",
    "# As an example, let me show you what a good spearman correlation looks like:\n",
    "# name of the column that contains the isoform names:\n",
    "genes = 'target_id'\n",
    "\n",
    "# the genotypes to compare\n",
    "letters = ['e', 'c']\n",
    "\n",
    "# extract the dataframes from the morgan.hunt object\n",
    "x = thomas.beta_filtered[letters[0]]\n",
    "y = thomas.beta_filtered[letters[1]]\n",
    "\n",
    "# boolean logic to find the stat. sig. diff. genes that appear in both x and y\n",
    "ovx = x[lind(x)]\n",
    "ovy = y[lind(y) & y[genes].isin(ovx[genes])].copy()\n",
    "ovx = x[lind(x) & x[genes].isin(ovy[genes])].copy()\n",
    "\n",
    "# a function to rank order the data\n",
    "def find_rank(df):\n",
    "    \"\"\"A function to find the rank values of a variable.\"\"\"\n",
    "    # make a copy of the dataframe, then sort it inplace\n",
    "    d = df.copy()\n",
    "    d.sort_values('b', inplace=True)\n",
    "    # make a rank vector and append it to the sorted dataframe\n",
    "    rank = np.linspace(0, len(d)-1, len(d))\n",
    "    d['r'] = rank\n",
    "    # sort by isoform name again and return the modified df\n",
    "    d.sort_values('target_id', inplace=True)\n",
    "    return d\n",
    "\n",
    "# apply said function\n",
    "ovx = find_rank(ovx)\n",
    "ovy = find_rank(ovy)\n",
    "\n",
    "# calculate a linear regression on ranked data, which is equivalent to Spearman Ranked Regression\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(ovx.r,ovy.r)\n",
    "\n",
    "# We make two vectors in order to draw the best fit line on a plot\n",
    "X = np.linspace(0, len(ovx.r))\n",
    "Y = slope*X + intercept\n",
    "\n",
    "# Plot the genes that are statistically significantly altered in both X and Y\n",
    "plt.plot(ovx.r, ovy.r, 'ro', alpha=1, label='Overlapped Diff. Exp. Genes')\n",
    "\n",
    "# Plot the best fit line\n",
    "plt.plot(X, Y, 'k-', alpha=0.6, lw=10, label= 'Best Fit')\n",
    "\n",
    "# prettify the plot\n",
    "plt.title('Linear Pathways Share a\\nCommon Transcriptomic Phenotype', fontsize=ft).\\\n",
    "            set_path_effects([path_effects.Normal()])\n",
    "plt.xlabel(genotype_mapping[letters[0]], fontsize=30).set_path_effects([path_effects.Normal()])\n",
    "plt.ylabel(genotype_mapping[letters[1]], fontsize=30).set_path_effects([path_effects.Normal()])\n",
    "plt.xticks(fontsize=20)\n",
    "plt.savefig('../output/spearmanr_b_and_c.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman R predicts a trend, but the best fit we found doesn't agree with the one I would predict with my eye. We can probably do better if we use a Bayesian regression that minimizes least squares but using a Student-T Prior, NOT a Gaussian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Robust Regression\n",
    "In order to perform the Spearman regression, this is what I will do:\n",
    "\n",
    " * Extract the pertinent datasets for the two genotypes I want to convert.\n",
    " * Find the genes that are altered between both conditions, regardless of direction\n",
    " * After finding this overlap, rank the genes by their $\\beta$ coefficient in each dataset\n",
    " * Perform Least Squares on the ranked data, but use a Student-T instead of a Gaussian prior.\n",
    "   * The regression in this case is sampled using a full Monte Carlo Simulation.\n",
    " * Identify outliers to this regression, and run a second regression on outliers to see if there are complex regulatory relationships between these genes.\n",
    " * Plot the results\n",
    " \n",
    "In other words, given ranked data, I will find the line that is likeliest to explain the data by finding:\n",
    "\\begin{equation}\n",
    "P(D | \\mu, \\sigma) \\propto \\prod_i \\mathrm{StudentT}(D_i(x) - \\mu(x), \\sigma)\n",
    "\\end{equation}\n",
    "\n",
    "The Student-T distribution has considerably heavier tails than a Gaussian distribution, so it will not consider the evidence provided by outliers as informative as a Gaussian would. \n",
    "\n",
    "In order to perform this simulation, we will use the **pymc3** package to specify the model. This model was inspired and successfully deployed thanks to Thomas Wiecki; specifically thanks to [this blog entry](http://twiecki.github.io/blog/2013/08/27/bayesian-glms-2/) by him. Thanks Tom!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4. Complex Regulation Generates Detectable Patterns in Transcriptomes\n",
    "\n",
    "The code that we will run below was used to generate the bottom panel of figure 4 in our paper. The figure as is output here was only subjected to very minor aesthetic modifications post-generation (such as moving the title a little above where it appears here). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def robust_regress(data):\n",
    "    \"\"\"A robust regression using a StudentT distribution instead of a Gaussian model.\"\"\"\n",
    "    with pm.Model() as model_robust:\n",
    "        # set the model. pymc is nice because it will automatically choose\n",
    "        # appropriate priors for us once we specify our likelihood is StudentT\n",
    "        family = pm.glm.families.StudentT()\n",
    "        # specify we want a generalized linear model with a Student T distribution\n",
    "        pm.glm.glm('y ~ x', data, family=family)\n",
    "        # find the MAP as a good starting point\n",
    "        start = pm.find_MAP()\n",
    "        # do the simulation and return the results\n",
    "        step = pm.NUTS(scaling=start)\n",
    "        trace_robust = pm.sample(2000, step, progressbar=True)\n",
    "        return trace_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take the data from the Spearman example and put it into a dictionary to feed into the robust regression\n",
    "data = dict(x=ovx.r, y=ovy.r)\n",
    "\n",
    "x = np.linspace(ovx.r.min(), ovx.r.max())\n",
    "\n",
    "# perform the simulation\n",
    "trace_robust = robust_regress(data)\n",
    "\n",
    "# draw a figure\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# some statistics.\n",
    "# normalize everything so that all points are centered around 0\n",
    "# by taking the y-coordinates and subtracting the value of the model at the point we calculated\n",
    "distribution = ovy.r - trace_robust.Intercept.mean() - ovx.r*trace_robust.x.mean()\n",
    "# find the mean and stdev of the distribution (even though mean should be 0 now)\n",
    "mean = distribution.mean()\n",
    "std = distribution.std()\n",
    "\n",
    "# find inliers and outliers (see text description below)\n",
    "def find_inliers(distribution, mean, trace):\n",
    "    \"\"\"A function to identify inliers and outliers in a distribution\"\"\"\n",
    "    distribution_inliers = distribution[np.abs(distribution - mean)/(trace_robust.x.std() \n",
    "                                                                 + trace_robust.Intercept.std()+ std) < 1]\n",
    "    distribution_outliers = distribution[np.abs(distribution - mean)/(trace_robust.x.std() \n",
    "                                                                 + trace_robust.Intercept.std()+ std) > 1]\n",
    "\n",
    "    # get the gene names of the outliers\n",
    "    outliers = ovy[ovy.r.isin(distribution_outliers + \n",
    "                          trace_robust.Intercept.mean() + ovx.r*trace_robust.x.mean())].target_id\n",
    "    return distribution_inliers, distribution_outliers, outliers\n",
    "\n",
    "# call the function\n",
    "distribution_inliers, distribution_outliers, outliers = find_inliers(distribution, mean, trace_robust)\n",
    "\n",
    "# run a secondary regression on the outliers\n",
    "data2 = dict(x=ovx[ovx.target_id.isin(outliers)].r, y=ovy[ovy.target_id.isin(outliers)].r)\n",
    "trace_robust2 = robust_regress(data2)\n",
    "\n",
    "# get the y-coordinate of the inliers and outliers\n",
    "yri = distribution_inliers + trace_robust.Intercept.mean() + ovx.r*trace_robust.x.mean()\n",
    "yro = distribution_outliers + trace_robust.Intercept.mean() + ovx.r*trace_robust.x.mean()\n",
    "\n",
    "# plot the regression lines\n",
    "pm.glm.plot_posterior_predictive(trace_robust, eval=x, \n",
    "                                 label='posterior predictive regression lines',\n",
    "                                 color='#357EC7')\n",
    "pm.glm.plot_posterior_predictive(trace_robust2, eval=x, \n",
    "                                 label='posterior predictive regression lines',\n",
    "                                 color='#FFA500')\n",
    "\n",
    "# plot the data. Inliers are plotted as large green dots, outliers as small red dots\n",
    "plt.plot(ovx.r, yri, 'go', ms = 7.5)\n",
    "plt.plot(ovx[yro > 0].r, yro[yro > 0], 'ro', ms = 5)\n",
    "\n",
    "# prettify plot\n",
    "plt.xlim(0, len(ovx))\n",
    "plt.ylim(0, len(ovy))\n",
    "plt.yticks([0, 200, 400], fontsize=22)\n",
    "plt.xticks([0, 200, 400], fontsize=22)\n",
    "pathify('Transcriptome Reflects Multiple Interaction Modes', r'\\emph{rhy-1} genes ranked by $\\beta$', \n",
    "        r'\\emph{hif-1} genes ranked by $\\beta$', labelsize=24)\n",
    "plt.savefig('../output/multiple_modes_{0}.pdf'.format(letters[0]+letters[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, much better! Penalizing outliers allows us to estimate the primary regression slope really well (blue lines). Here, each blue line is the result of a simulation, and we can see that they are all clustered together. Having estimated the first regression, we can proceed to identify outliers. \n",
    "\n",
    "Now, there are multiple ways to identify outliers, and this is the point where I am going to cheat just a little bit. If we pretend that the model is gaussian (it isn't), then we can identify outliers (fairly aggressively) via the following method. Thus, if\n",
    "\n",
    "\\begin{equation}\n",
    "z(i) = \\frac{D_i(x) - \\mu(x)}{\\sigma_\\mu + \\sigma_{\\mathrm{Intercept}} + \\sigma_\\mathrm{Data}} > 1\n",
    "\\end{equation}\n",
    "\n",
    "then $z(i)$ is an outlier. \n",
    "\n",
    "After identifying these outliers, I can then pool them and run a second regression on them (orange lines). These lines are also quite clustered, and the slope is practically 1! Wow!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2. Positive Regulatory Relationships Can Be Identified By Transcriptomic Correlation\n",
    "\n",
    "In the above example, we saw that *rhy-1* and *hif-1* share a complex regulatory relationship as exhibited by the cross-pattern. However, an important point is whether or not this cross pattern appears in all datasets. While we cannot generalize yet (this kind of analysis is very new) we should definitely make sure that not all of our genes are exhibiting this cross pattern. Below, I show some a pair of genes that don't exhibit a cross pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genes = 'target_id'\n",
    "\n",
    "letters = ['b', 'd']\n",
    "\n",
    "# datasets\n",
    "x = thomas.beta_filtered[letters[0]]\n",
    "y = thomas.beta_filtered[letters[1]]\n",
    "\n",
    "# overlap\n",
    "ovx = x[lind(x)]\n",
    "ovy = y[lind(y) & y[genes].isin(ovx[genes])].copy()\n",
    "ovx = x[lind(x) & x[genes].isin(ovy[genes])].copy()\n",
    "\n",
    "# find rank\n",
    "ovx = find_rank(ovx)\n",
    "ovy = find_rank(ovy)\n",
    "\n",
    "# Set up MCMC parameters\n",
    "data = dict(x=ovx.r, y=ovy.r)\n",
    "\n",
    "x = np.linspace(ovx.r.min(), ovx.r.max())\n",
    "    \n",
    "# simulation\n",
    "trace_robust = robust_regress(data)\n",
    "\n",
    "# canvas\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# statistics\n",
    "distribution =ovy.r - trace_robust.Intercept.mean() - ovx.r*trace_robust.x.mean()\n",
    "mean = distribution.mean()\n",
    "std = distribution.std()\n",
    "\n",
    "# find the inliers and outliers\n",
    "distribution_inliers, distribution_outliers, outliers = find_inliers(distribution, mean, trace_robust)\n",
    "\n",
    "# y-coordinate of outliers\n",
    "yri = distribution_inliers + trace_robust.Intercept.mean() + ovx.r*trace_robust.x.mean()\n",
    "yro = distribution_outliers + trace_robust.Intercept.mean() + ovx.r*trace_robust.x.mean()\n",
    "\n",
    "# plot primary regression\n",
    "pm.glm.plot_posterior_predictive(trace_robust, eval=x, \n",
    "                                 label='posterior predictive regression lines',\n",
    "                                 color='#357EC7')\n",
    "\n",
    "# plot inliers and outliers\n",
    "plt.plot(ovx.r, yri, 'go', ms = 7.5)\n",
    "plt.plot(ovx[yro > 0].r, yro[yro > 0], 'ro', ms = 5)\n",
    "\n",
    "# prettify\n",
    "plt.xlim(0, len(ovx))\n",
    "plt.ylim(0, len(ovy))\n",
    "plt.yticks([0, 200, 400], fontsize=20)\n",
    "plt.xticks([0, 200, 400], fontsize=20)\n",
    "pathify('Positive Genetic Interactions', r'\\emph{egl-9} genes ranked by $\\beta$', \n",
    "        r'\\emph{vhl-1} genes ranked by $\\beta$')\n",
    "plt.savefig('../output/positive interaction{0}.pdf'.format(letters[0]+letters[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise Analysis of All Genes Using Spearman Correlation\n",
    "\n",
    "Given what we found above, we know that the spearman analysis is good to use to get a rough fast idea of how our data looks. Let's go ahead and run the analysis for all pairwise comparisons that can be made using this dataset. \n",
    "\n",
    "Spearman correlations and hypergeometric tests can be performed using the class morgan.brenner. \n",
    "\n",
    "Once I calculate the quantities of interest, I will plot them on a heatmap. However, reader beware. Do NOT **EVER** use jet. The red and blue heatmaps? Awful. They have very serious pathologies that have been well described, and they generate patterns via optical illusions. Instead, we will use the *viridis* colormap, which was used by scientists in LIGO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a 'genes' variable that will be used for labelling every plot from here on out:\n",
    "genes = [genotype_mapping[x] for x in thomas.single_mutants]\n",
    "\n",
    "# Define a plotting function to plot only a triangular heat map\n",
    "def tri_plot(matrix, xlabels, ylabels=[]):\n",
    "    \"\"\"Given a matrix, a set of xlabels and ylabels, draw a triangle plot.\"\"\"\n",
    "    # Minimum and maximum for colormap\n",
    "    vmin= matrix.min().min()\n",
    "    vmax= np.max(matrix).max()\n",
    "\n",
    "    # if user didn't specify xlabels, assume ylabels are the same as xlabels\n",
    "    if len(ylabels) == 0:\n",
    "        ylabels = xlabels\n",
    "\n",
    "    # make the lower triangle of the matrix, since we are only dealing with \n",
    "    # symmetric matrices. Also, remove the diagonal\n",
    "    mask = np.zeros_like(matrix)\n",
    "    mask[np.tril_indices_from(mask)] = True\n",
    "\n",
    "    # draw and adjust xtick size\n",
    "    with sns.axes_style(\"white\"):\n",
    "        ax = sns.heatmap(matrix, xticklabels=xlabels, yticklabels=ylabels, cmap='viridis',\n",
    "                         mask=mask, square=True, vmin=vmin, vmax=vmax)\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "\n",
    "# Perform Correlation Analysis\n",
    "sydney = morgan.brenner('spearman', thomas)\n",
    "# Plot\n",
    "tri_plot(sydney.rho.as_matrix(columns=thomas.single_mutants), genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So maybe *egl-9* and *rhy-1* interact? Let's wait for the full Bayesian treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypergeometric Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = sydney.hyper_minus.as_matrix(columns=thomas.single_mutants)\n",
    "genes = [genotype_mapping[x] for x in thomas.single_mutants]\n",
    "tri_plot(mat, genes)\n",
    "pathify('Negative Genetic Interaction\\nProbability', '', '')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "plt.savefig('../output/probability_of_inhibition_single_mutants.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Using Robust Regression\n",
    "\n",
    "What I do here is try to identify trends. Namely, for two genotypes X and Y, I fit a line using a Bayesian robust regression (see methods) thru the rank-ordered regression coefficients that are statistically significantly different from 0 and that are present in both X and Y. Next, I use this Bayesian framework to identify any and all outliers to the regression. \n",
    "\n",
    "In order to test for alternative modes of interaction in this dataset, I take the outliers and I run the same regression again *on the outliers*. If this second interaction has an opposite sign to the first, then we predict that there are two modes of interaction, subject to the following caveats:\n",
    "\n",
    " * Both the primary and secondary regressions yield strong correlations (>0.7)\n",
    " * The first regression results in many outliers\n",
    "\n",
    "Finally, because of the approach I used, I can also predict which genes are under what mode of regulation. Super cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barbara = morgan.mcclintock('bayesian', thomas, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation has finished, and now I should make the heat map showing the primary correlations.\n",
    "\n",
    "## Figure 3. Pairwise regression values between all single mutants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = barbara.robust_slope.as_matrix(columns=thomas.single_mutants)\n",
    "tri_plot(mat, genes)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "pathify('Robust Bayesian Correlations Predict Interaction Between Genes', '', '')\n",
    "plt.savefig('../output/bayes_primary_single_mutants.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the secondary correlations and see what comes out of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = barbara.secondary_slope.as_matrix(columns=thomas.single_mutants)\n",
    "tri_plot(mat, genes)\n",
    "plt.title('Robust Bayesian Correlations Predict Interaction Between Genes', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting functional relationships between genes\n",
    "\n",
    "Another way to plot the results from the regression above is to make scatterplots. For that, it's best to work with tidy dataframes. \n",
    "What I will do next is the following:\n",
    "\n",
    "Take the square correlation matrix I calculated above. Place it in a [tidy dataframe](http://vita.had.co.nz/papers/tidy-data.pdf). Concatenate this dataframe to include both primary and secondary relationships. Add a column that contains an indicator variable specifying whether the primary and the secondary regressions have different sign. If they don't have different signs, then add the correlations together. The reasoning for this is that:\n",
    "\n",
    "\\begin{equation}\n",
    "w_1\\rho + w_2\\rho = (w_1+w_2)\\rho\n",
    "\\end{equation}\n",
    "\n",
    "In other words, we expect the correlation coefficient to be the same between the primary and secondary correlation and performing this is heuristically the same as adding the weights together. I know there's a better way to do this, and I am actively working on implementing this is in a proper manner. In the future, the weights will be added, and the secondary regression wil be discarded. \n",
    "\n",
    "Finally, I order the pairs of genes to reflect decreasing functional distance and plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tidy_df(df, corr='corr'):\n",
    "    \"\"\"\n",
    "    A function that returns a tidied up dataframe.\n",
    "    \n",
    "    Dataframe provided must be the result of morgan.robust_regression()\n",
    "    or morgan.robust_regression_secondary()\n",
    "    \n",
    "    df - dataframe to tidy up\n",
    "    corr - please specify whether this dataframe is from morgan.robust_regression (write 'corr')\n",
    "    or from morgan.robust_regression_secondary() (write 'outlier')\n",
    "    \n",
    "    outputs:\n",
    "    df - a tidied dataframe with columns 'corr_wit', 'variable', 'fraction' and 'pair'\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['corr_with'] = thomas.single_mutants\n",
    "    df = pd.melt(df, id_vars='corr_with')\n",
    "    df = df[df.corr_with != df.variable]\n",
    "\n",
    "    def add_fraction_outliers(x, fraction='corr'):\n",
    "        if (x.corr_with, x.variable) in barbara.correlated_genes.keys():\n",
    "            dd = barbara.correlated_genes[(x.corr_with, x.variable)]\n",
    "            outliers = len(dd['outliers'])\n",
    "            corr = len(dd['corr'])\n",
    "            total = outliers + corr\n",
    "            if fraction == 'corr':\n",
    "                return corr/total\n",
    "            else:\n",
    "                return outliers/total\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    df['fraction_outliers'] = df.apply(add_fraction_outliers, args=(corr,), axis=1)\n",
    "    df['pair'] =  df.variable + df.corr_with\n",
    "    return df\n",
    "\n",
    "def different(x):\n",
    "    p = x.pair\n",
    "    primary = d[(d.pair == p) & (d.regression == 'primary')].value.values[0]\n",
    "    secondary = d[(d.pair == p) & (d.regression == 'secondary')].value.values[0]\n",
    "    \n",
    "    if primary == 0 or secondary == 0:\n",
    "        return 0\n",
    "    elif (primary*secondary > 0):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def special_add(x):\n",
    "    if x.regression == 'secondary':\n",
    "        if x.different == -1:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return x.value\n",
    "    if d[(d.regression=='secondary') & (d.pair == x.pair)].different.values == -1:\n",
    "        to_add = d[(d.regression=='secondary') & (d.pair == x.pair)].value.values[0]\n",
    "        return x.value + to_add\n",
    "    else:\n",
    "        return x.value\n",
    "\n",
    "d_pos = tidy_df(barbara.robust_slope)\n",
    "d_pos['regression'] = 'primary'\n",
    "d_minus = tidy_df(barbara.secondary_slope, corr='outliers')\n",
    "d_minus['regression'] = 'secondary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4. Weighted Correlations Reflect Functional Distance\n",
    "\n",
    "Now we can plot the weighted correlations, making sure that they are ordered by functional distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = [d_pos, d_minus]\n",
    "d = pd.concat(frames)\n",
    "d['different'] = d.apply(different, axis=1)\n",
    "d.dropna(subset=['fraction_outliers'], inplace=True)\n",
    "d['corrected'] = d.apply(special_add, axis=1)\n",
    "d.dropna(subset=['corrected'], inplace=True)\n",
    "d['sort_pairs'] = d.pair.map(sort_pairs)\n",
    "d.sort('sort_pairs', inplace=True)\n",
    "d['genes'] = d.pair.map(decode_pairs)\n",
    "sns.stripplot(x='genes', y='corrected', data=d[d.regression=='primary'], size=20, color='g')\n",
    "plt.xticks(rotation=45, fontsize=20)\n",
    "plt.yticks([-0.1, 0, 0.5], fontsize=20)\n",
    "plt.axhline(0, lw=2, ls='--', color='gray')\n",
    "pathify('Weighted Correlations Reflect Functional Distance',\n",
    "        'Pairs of Genes, Ordered by Decreasing Functional Distance',\n",
    "       'Primary Correlation, Normalized to Overlap')\n",
    "plt.savefig('../output/weighted_corr_decreases_w_distance.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.stripplot(x='genes', y='corrected', \n",
    "              data=d[(d.regression=='secondary') & (d.different == 1)], size=10, color='k')\n",
    "plt.axhline(0, ls='--', color='0.5')\n",
    "plt.xticks(rotation=45, fontsize=20)\n",
    "plt.yticks([-0.1, 0, 0.1], fontsize=20)\n",
    "plt.axhline(0, lw=2, ls='--', color='gray')\n",
    "plt.ylabel('Secondary Correlation, Normalized to Overlap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that 'C' and 'B' and 'C' and 'E' interact in both a positive and negative manner and both correlations are well supported by evidence. Intriguing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Mutant Analysis\n",
    "\n",
    "With double mutants, the analysis gets slightly more complicated. Now we're getting into full pathways!\n",
    "\n",
    "A first approach is to inspect the double mutants by Spearman correlation analysis to the single mutants that make them up. A quick visualization will show us any epistasis and the extent of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f e\n",
      "Applied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.7 secf d\n",
      "Applied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.6 secf c\n",
      "Applied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.5 secf b\n",
      "Applied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.5 seca e\n",
      "Applied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 2.3 seca d\n",
      "Applied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.9 seca c\n",
      "Applied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.9 seca b\n",
      "Applied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 2.3 secApplied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.4 secApplied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.4 secApplied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.4 secApplied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.5 secApplied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.5 secApplied log-transform to lam and added transformed lam_log_ to model.\n",
      " [-----------------100%-----------------] 2000 of 2000 complete in 1.5 secApplied log-transform to lam and added transformed lam_log_ to model.\n"
     ]
    }
   ],
   "source": [
    "alfred = morgan.sturtevant('epistasis analysis')\n",
    "alfred.epistasis_analysis(thomas)\n",
    "alfred.epistasis_secondary(thomas, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alfred.epistasis['double_corr'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alfred.epistasis['unweighted'] = alfred.epistasis.correlation/alfred.epistasis.weights\n",
    "\n",
    "\n",
    "alfred.epistasis['double mutant'] = alfred.epistasis.double_mutant.map(genotype_mapping)\n",
    "alfred.epistasis['corr with'] = alfred.epistasis.corr_with.map(genotype_mapping)\n",
    "\n",
    "sns.stripplot(x='double mutant', y='unweighted', hue='corr with', data=alfred.epistasis, size=15, jitter=True)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.axhline(0, ls='--', color='0.5')\n",
    "plt.yticks([-0.2, 0.5, 1], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.stripplot(x='double mutant', y='correlation', hue='corr with', data=alfred.epistasis, size=15, jitter=True)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.axhline(0, ls='--', color='0.5')\n",
    "plt.yticks([-0.1, 0.2, 0.4], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alfred.epistasis_secondary['unweighted'] = alfred.epistasis_secondary.correlation/alfred.epistasis_secondary.weights\n",
    "alfred.epistasis_secondary['fractional corr'] = alfred.epistasis_secondary.correlation/alfred.epistasis.correlation.abs()\n",
    "\n",
    "alfred.epistasis_secondary['double mutant'] = alfred.epistasis_secondary.double_mutant.map(genotype_mapping)\n",
    "alfred.epistasis_secondary['corr with'] = alfred.epistasis_secondary.corr_with.map(genotype_mapping)\n",
    "\n",
    "\n",
    "sns.stripplot(x='double mutant', y='unweighted', hue='corr with', data=alfred.epistasis_secondary,\n",
    "              size=15, jitter=True)\n",
    "plt.xticks(fontsize=20)\n",
    "# plt.ylim(-1.1, 1.1)\n",
    "# plt.axhline(0, ls='--', color='0.5')\n",
    "# plt.yticks([-1, 0, 1], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.stripplot(x='double mutant', y='correlation', hue='corr with', data=alfred.epistasis_secondary,\n",
    "              size=15, jitter=True)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.ylim(-1.1, 1.1)\n",
    "plt.axhline(0, ls='--', color='0.5')\n",
    "plt.yticks([-1, 0, 1], fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def quadrature(x):\n",
    "    def square(x):\n",
    "        return x**2\n",
    "    return np.sqrt(np.sum(x.apply(square)))\n",
    "\n",
    "double = 'f'\n",
    "for key in barbara.correlated_genes.keys():\n",
    "    pair = key[0] + key[1]\n",
    "    if pair not in d.pair.unique():\n",
    "        pair = key[1] + key[0]\n",
    "\n",
    "    pred_genes = barbara.correlated_genes[key]['corr']\n",
    "    if (pair != thomas.double_muts[double]):\n",
    "        continue\n",
    "    \n",
    "    df_pred = thomas.beta[key[0]].copy()\n",
    "    df_pred = df_pred[df_pred.target_id.isin(pred_genes)]\n",
    "    df_test = thomas.beta[double]\n",
    "    df_test = df_test[df_test.target_id.isin(pred_genes) & (df_test.qval< 0.1)].copy()\n",
    "    df_pred = df_pred[df_pred.target_id.isin(df_test.target_id)]\n",
    "    df_test = find_rank(df_test)\n",
    "    df_pred = find_rank(df_pred)\n",
    "    \n",
    "    df_ultimate = thomas.beta[key[1]].copy()\n",
    "    df_ultimate['b_2'] = thomas.beta[key[0]].b\n",
    "    df_ultimate['b'] = (df_ultimate.b + df_ultimate.b_2)/2\n",
    "    df_ultimate = df_ultimate[df_ultimate.target_id.isin(pred_genes)]\n",
    "    df_ultimate = df_ultimate[df_ultimate.target_id.isin(df_test.target_id)]\n",
    "    df_ultimate = find_rank(df_ultimate)\n",
    "    print(len(df_ultimate), len(df_test))\n",
    "    \n",
    "    plt.errorbar(df_ultimate.b, df_test.b - df_ultimate.b,\n",
    "                 xerr=df_ultimate.se_b, yerr=df_test.se_b, fmt='go', alpha=0.2, ms=4)\n",
    "    plt.errorbar(df_pred.b, df_test.b - df_pred.b,\n",
    "                 xerr=df_ultimate.se_b, yerr=df_test.se_b, fmt='bo', alpha=0.2, ms=4)\n",
    "    \n",
    "    lr = scipy.stats.linregress(df_ultimate.b, df_test.b)\n",
    "    lr2 = scipy.stats.linregress(df_pred.b, df_test.b)\n",
    "    \n",
    "    wls = sm.WLS(df_test.b- df_ultimate.b, df_ultimate.b, weights=1. / df_ultimate.se_b**2)\n",
    "    res_wls = wls.fit()\n",
    "    \n",
    "    wls2 = sm.WLS(df_test.b- df_pred.b, df_pred.b, weights=1. / df_pred.se_b**2)\n",
    "    res_wls2 = wls2.fit()\n",
    "    \n",
    "    slope = res_wls.params\n",
    "    slope2 = res_wls2.params\n",
    "\n",
    "    print(key[1], res_wls.summary())\n",
    "    print(key[0], res_wls2.summary())\n",
    "\n",
    "    y = x*slope.b\n",
    "    y2 = x*slope2.b\n",
    "    plt.plot(x, y, 'g-', lw=2)\n",
    "    plt.plot(x, y2, 'b-', lw=2)\n",
    "    prediction = df_ultimate.b + lr.intercept\n",
    "    mnh = scipy.stats.linregress(df_ultimate.b, df_test.b - prediction)\n",
    "\n",
    "    plt.xlim(-8,8)\n",
    "    plt.ylim(-8,8)\n",
    "    # plt.xscale('symlog')\n",
    "    # plt.yscale('symlog')\n",
    "    print(key[1], lr)\n",
    "    print(key[0], lr2)\n",
    "    print(df_pred.b.abs().mean())\n",
    "    print(\n",
    "\"\"\"\n",
    "{0}: mean b = {3:.2g} +/- {6:.2g}\n",
    "{1}: mean b = {4:.2g} +/- {7:.2g}\n",
    "{2}: mean b = {5:.2g} +/- {8:.2g}\n",
    "\"\"\".format(key[0], key[1], pair,\n",
    "          df_pred.b.abs().mean(), df_ultimate.b.abs().mean(), df_test.b.abs().mean(),\n",
    "          (df_pred.b.abs().std() + quadrature(df_pred.se_b))/np.sqrt(len(df_pred)),\n",
    "          (df_ultimate.b.abs().std() + quadrature(df_pred.se_b))/np.sqrt(len(df_pred)),\n",
    "          (df_test.b.abs().std() + quadrature(df_pred.se_b))/np.sqrt(len(df_pred)),\n",
    "          )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, value in thomas.double_muts.items():\n",
    "    x = thomas.beta_filtered[key]\n",
    "    y = thomas.beta_filtered[value[0]]\n",
    "    z = thomas.beta_filtered[value[1]]\n",
    "    \n",
    "    x = x[x.qval < thomas.q]\n",
    "    y = y[y.qval < thomas.q]\n",
    "    z = z[z.qval < thomas.q]\n",
    "    \n",
    "    yANDz = len(y[y.target_id.isin(z)])\n",
    "    yORz = len(y) + len(z)\n",
    "    expected = yORz - yANDz\n",
    "    \n",
    "    pred1 = x[(x.target_id.isin(z.target_id))]\n",
    "    pred2 = x[x.target_id.isin(y.target_id)]\n",
    "    \n",
    "    pred = len(list(set(pred1.target_id.tolist() + pred2.target_id.tolist())))\n",
    "    \n",
    "    print('Expected: ', expected)\n",
    "    print('Observed: ', len(x))\n",
    "    print('Predicted: ', pred)\n",
    "    print('Observed/Expected: {0:.2g}'.format(len(x)/expected))\n",
    "    print('Predicted/Expected: {0:.2g}'.format(pred/expected))\n",
    "    print('Surprise factor: {0:.2g}'.format(pred/len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double mutants:\n",
    "$$\n",
    "a = b^-d^-\n",
    "$$\n",
    "\n",
    "$$\n",
    "f = b^-c^-\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letters = ['a', 'c']\n",
    "\n",
    "x = thomas.beta_filtered[letters[0]]\n",
    "y = thomas.beta_filtered[letters[1]]\n",
    "\n",
    "ovx = x[lind(x)]\n",
    "ovy = y[lind(y) & y.target_id.isin(ovx.target_id)].copy()\n",
    "ovx = x[lind(x) & x.target_id.isin(ovy.target_id)].copy()\n",
    "\n",
    "ovx = find_rank(ovx)\n",
    "ovy = find_rank(ovy)\n",
    "\n",
    "data = dict(x=ovx.r, y=ovy.r)\n",
    "\n",
    "x = np.linspace(ovx.r.min(), ovx.r.max())\n",
    "    \n",
    "trace_robust = robust_regress(data)\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "distribution =ovy.r - trace_robust.Intercept.mean() - ovx.r*trace_robust.x.mean()\n",
    "mean = distribution.mean()\n",
    "std = distribution.std()\n",
    "\n",
    "# find the inliers and outliers\n",
    "distribution_inliers, distribution_outliers, outliers = find_inliers(distribution, mean, trace_robust)\n",
    "\n",
    "data2 = dict(x=ovx[ovx.target_id.isin(outliers)].r, y=ovy[ovy.target_id.isin(outliers)].r)\n",
    "trace_robust2 = robust_regress(data2)\n",
    "\n",
    "\n",
    "yri = distribution_inliers + trace_robust.Intercept.mean() + ovx.r*trace_robust.x.mean()\n",
    "yro = distribution_outliers + trace_robust.Intercept.mean() + ovx.r*trace_robust.x.mean()\n",
    "\n",
    "plt.plot(ovx.r, yri, 'go', ms = 6)\n",
    "plt.plot(ovx.r, yro, 'ro', ms = 5)\n",
    "pm.glm.plot_posterior_predictive(trace_robust, eval=x, \n",
    "                                 label='posterior predictive regression lines',\n",
    "                                 color='#357EC7')\n",
    "pm.glm.plot_posterior_predictive(trace_robust2, eval=x, \n",
    "                                 label='posterior predictive regression lines',\n",
    "                                 color='#FFA500')\n",
    "plt.xlim(0, len(ovx))\n",
    "# plt.legend()\n",
    "\n",
    "if np.abs(trace_robust.x.mean()) > 0.6 and np.abs(trace_robust2.x.mean()) > 0.6:\n",
    "    t1 = trace_robust.x.mean()/np.abs(trace_robust.x.mean())\n",
    "    t2 = trace_robust2.x.mean()/np.abs(trace_robust2.x.mean())\n",
    "    if t1 == -t2:\n",
    "        print('Complex Regulation at Work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Hypoxia Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find all the genes in the hypoxia response:\n",
    "ovb = thomas.beta_filtered['b'].copy()\n",
    "ovd = thomas.beta_filtered['d']\n",
    "ove = thomas.beta_filtered['e']\n",
    "\n",
    "ovb['d_qval'] = ovd.qval\n",
    "ovb['e_qval'] = ove.qval\n",
    "\n",
    "ovb['d_b'] = ovd.b\n",
    "ovb['e_b'] = ove.b\n",
    "\n",
    "# qvalue cutoff\n",
    "ind1 = (ovb.qval < 0.1)\n",
    "ind2 = (ovb.d_qval < 0.1)\n",
    "ind3 = (ovb.e_qval < 0.1)\n",
    "\n",
    "# make sure they all go in the same direction:\n",
    "ind4 = (ovb.b*ovb.d_b > 0) & (ovb.b*ovb.e_b > 0) & (ovb.d_b*ovb.e_b >0)\n",
    "\n",
    "hypoxia_genes = ovb[ind1 & ind2 & ind3 & ind4].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(hypoxia_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tissue_df = tea.fetch_dictionary()\n",
    "df_res, unused = tea.enrichment_analysis(hypoxia_genes.ens_gene, tissue_df, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hypoxia_genes['avg_qval'] = (hypoxia_genes.qval + hypoxia_genes.e_qval + hypoxia_genes.d_qval)/3\n",
    "hypoxia_genes['avg_b'] = (hypoxia_genes.b + hypoxia_genes.d_b + hypoxia_genes.e_b)/3\n",
    "hypoxia_genes.sort_values(['avg_qval'], inplace=True)\n",
    "hypoxia_genes.to_csv('../output/hypoxia_high_confidence.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The genes upregulated by *egl-9* should be down in *hif-1*.\n",
    "\n",
    "However, egl-9 and hif-1 seem to have a positive primary relationship under normoxic conditions. Are the secondary genes associated with the hypoxia response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First, identify the genes that are outliers in the bc, ec response and intersect them.\n",
    "if ('c', 'b') in barbara.correlated_genes.keys():\n",
    "    key = ('c', 'b')\n",
    "else:\n",
    "    key = ('b', 'c')\n",
    "\n",
    "if ('c', 'e') in barbara.correlated_genes.keys():\n",
    "    key2 = ('c', 'e')\n",
    "else:\n",
    "    key2 = ('e', 'c')\n",
    "\n",
    "print(key)\n",
    "bc_in = barbara.correlated_genes[key]['corr']\n",
    "ec_in = barbara.correlated_genes[key2]['corr']\n",
    "bec_in = np.intersect1d(bc_in, ec_in)\n",
    "print(\"\"\"\n",
    "There are {0} genes that are inliers in the BC intersection,\n",
    "There are {1} genes that are inliers in the EC intersection,\n",
    "and there are {2} genes in the BEC inliers intersection.\n",
    "\"\"\".format(len(bc_in), len(ec_in), len(bec_in)))\n",
    "\n",
    "\n",
    "bc = barbara.correlated_genes[key]['outliers'].target_id\n",
    "ec = barbara.correlated_genes[key2]['outliers'].target_id\n",
    "bec = np.intersect1d(bc, ec)\n",
    "print(\"\"\"\n",
    "There are {0} genes that are outliers in the BC intersection,\n",
    "There are {1} genes that are outliers in the EC intersection,\n",
    "and there are {2} genes in the BEC outlier intersection.\n",
    "\"\"\".format(len(bc), len(ec), len(bec)))\n",
    "\n",
    "print(\n",
    "\"\"\"\n",
    "{0:.2g} of the genes in the BEC intersection are outliers\n",
    "\"\"\".format(len(bec)/(len(bec) + len(bec_in)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection = hypoxia_genes[hypoxia_genes.target_id.isin(bec)].ext_gene.unique()\n",
    "print(\n",
    "\"\"\"\n",
    "There are {} genes from the BEC intersection in the hypoxia set!\n",
    "\"\"\".format(len(intersection))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = thomas.beta_filtered['a'].shape[0] # total genes measured for any experiment\n",
    "\n",
    "p = stats.hypergeom.sf(len(intersection), L, len(bec), len(hypoxia_genes))\n",
    "\n",
    "if p < 10**-3:\n",
    "    print(\n",
    "\"\"\"\n",
    "This result is statistically significant, with p-value = {0:.2g}\n",
    "\"\"\".format(p)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, it does seem that hypoxia related genes are under control of *hif-1* under normoxic conditions, and that knocking *hif-1* out in a normoxic animal causes changes in this gene set. However, this is not the PRIMARY role of *hif-1* under physiologic conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = thomas.beta_filtered['c']\n",
    "temp[temp.target_id.isin(intersection)].qval.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, none of them are immediately associated with the hypoxia pathway, but a number of these are stress response genes! Thankfully, the q-values are also reasonably low for most of these genes. We're all good. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Control\n",
    "\n",
    "Load up the hypoxia gold standard Carmie gave me. These genes are expected to go up in everything except in Hif-1. \n",
    "\n",
    "By this point, I have solved the network, I guessed which gene was Hif-1 and I have been told the identities of the genes. \n",
    "\n",
    "C = Hif-1  \n",
    "B = egl-9  \n",
    "D = vhl-1  \n",
    "E = rhy-1  \n",
    "\n",
    "nhr-57 is an important gene for hypoxia. WBID is WBGene00003647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Figure out how many hits we get and if the pvalue is significant!\n",
    "for sm in thomas.single_mutants:\n",
    "    df = thomas.beta_filtered[sm]\n",
    "    ind = (genpy.find(df, hypoxia_gold.WBIDS, col='ens_gene'))\n",
    "    found = df[ind & (df.qval < 0.1)]\n",
    "    sig = df[df.qval < 0.1]\n",
    "    pval = stats.hypergeom.sf(len(found), len(df), len(hypoxia_gold), len(sig))\n",
    "    print('genotype: ', sm)\n",
    "    print('found: ', len(found), '      Mean b: {0:.2g}'.format(found.b.mean()))\n",
    "    print('pval: {0:.2g}'.format(pval))\n",
    "    \n",
    "    \n",
    "    print('Maximum change was:')\n",
    "    print(found[found.b == found.b.max()].ext_gene.values[0])\n",
    "    print(np.exp(found[found.b == found.b.max()].b.values)[0], ' fold change')\n",
    "    if 'WBGene00003647' in found.ens_gene.values:\n",
    "        nhr57 = np.exp(found[found.ens_gene == 'WBGene00003647'].b.values[0])\n",
    "        print('nhr-57 is in', sm, 'and its fold change was {0:.2g}'.format(nhr57))\n",
    "    \n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G=nx.Graph()\n",
    "\n",
    "mutant_dict = {'b': 'egl-9',\n",
    "               'c': 'hif-1',\n",
    "               'e': 'rhy-1',\n",
    "               'd': 'vhl-1',\n",
    "               'g': 'fog-2'\n",
    "              }\n",
    "\n",
    "for i, key in enumerate(thomas.single_mutants):\n",
    "    for j, key2 in enumerate(thomas.single_mutants):\n",
    "        df = d\n",
    "        r = d[(d.variable == key) & (d.corr_with == key2) &\n",
    "              (d.regression == 'primary')].corrected.values\n",
    "        if r:\n",
    "            G.add_edge(mutant_dict[key], mutant_dict[key2], weight=r[0])\n",
    "\n",
    "elarge=[(u,v) for (u,v,d) in G.edges(data=True)]\n",
    "width=[15*d['weight'] for (u,v,d) in G.edges(data=True)]\n",
    "weights=[d['weight'] for (u,v,d) in G.edges(data=True)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "pos=nx.spring_layout(G) # positions for all nodes\n",
    "\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=1500, node_color='g', alpha=.5)\n",
    "\n",
    "# edges\n",
    "edges = nx.draw_networkx_edges(G, pos, edgelist=elarge,\n",
    "                       width=width, edge_color=weights,\n",
    "                       edge_cmap=plt.cm.viridis)\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=15, font_family='sans-serif')\n",
    "\n",
    "fig.colorbar(edges)\n",
    "\n",
    "# plt.axis('off')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig(\"../output/weighted_graph.pdf\") # save as png\n",
    "plt.show() # display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An *in silico* qPCR experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorter = {'a': 6,\n",
    "          'f': 7,\n",
    "          'b': 2,\n",
    "          'c': 4,\n",
    "          'd':3,\n",
    "          'e': 1,\n",
    "          'g': 5\n",
    "         }\n",
    "\n",
    "x = ['WBGene00001851',\n",
    "     'WBGene00012324',\n",
    "     'WBGene00001178',\n",
    "     'WBGene00006922',\n",
    "     'WBGene00003647',\n",
    "     'WBGene00002248'\n",
    "    ]\n",
    "\n",
    "# run the experiment!\n",
    "def qPCR_prep(morgan, genelist):\n",
    "    g = []\n",
    "    data = np.array([])\n",
    "    i = 0\n",
    "    for genotype, df in thomas.beta.items():\n",
    "        for j, xi in enumerate(genelist):\n",
    "            geno = genotype_mapping[genotype]\n",
    "            y = df[(df.ens_gene == xi)][['ens_gene', 'ext_gene','b', 'se_b', 'qval']].values\n",
    "            if len(y) == 0:\n",
    "                continue\n",
    "            # hif has two isoforms, so take F38A6.3c\n",
    "            if y.shape[0] > 1:\n",
    "                y = df[(df.target_id == 'F38A6.3c')][['ens_gene', 'ext_gene','b', 'se_b', 'qval']].values\n",
    "            if len(data) == 0:\n",
    "                data = y\n",
    "            else:\n",
    "                data = np.vstack((data, y))\n",
    "            g += [genotype]\n",
    "        i += 1\n",
    "\n",
    "    d = pd.DataFrame(data, columns=['ens_gene', 'ext_gene', 'b', 'se_b', 'qval'])\n",
    "    d['code'] = g\n",
    "    d['genotype'] = d.code.map(genotype_mapping)\n",
    "    d['order'] = d.code.map(sorter)\n",
    "    d.sort_values('order', inplace=True)\n",
    "    d.reset_index(inplace=True)  \n",
    "    return d\n",
    "\n",
    "d = qPCR_prep(thomas, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a qPCR barplot\n",
    "temp = d\n",
    "index = np.linspace(0, temp.genotype.unique().shape[0]-1, temp.genotype.unique().shape[0])\n",
    "alpha = 0.7\n",
    "error_config = {'ecolor': '0.2'}\n",
    "\n",
    "plotting = {'rhy-1': 0,\n",
    "            'egl-9': 1,\n",
    "            'hif-1': 2,\n",
    "            }\n",
    "\n",
    "color = {'rhy-1': \"#ca0020\",\n",
    "         'egl-9': '#f4a582',\n",
    "         'hif-1': '#f7f7f7',\n",
    "         'nhr-57':'#92c5de',\n",
    "         'lam-3': '#0571b0'\n",
    "        }\n",
    "\n",
    "grouped = temp.groupby('ext_gene')\n",
    "\n",
    "bar_width = 1/(len(grouped)+1)\n",
    "\n",
    "for name, group in grouped:\n",
    "    if name not in plotting.keys():\n",
    "        where = max(plotting.keys(), key=lambda k: plotting[k])\n",
    "        val = plotting[where]\n",
    "        plotting[name] = val + 1\n",
    "    \n",
    "    add = plotting[name]*bar_width\n",
    "    if name in color.keys():\n",
    "        barlist = plt.bar(index + add, group.b.values, bar_width, alpha=alpha,\n",
    "                          yerr=group.se_b, error_kw=error_config, label=name,\n",
    "                          color=color[name])\n",
    "    else:\n",
    "        barlist = plt.bar(index + add, group.b.values, bar_width, alpha=alpha,\n",
    "                          yerr=group.se_b, error_kw=error_config, label=name)\n",
    "    sig = group.qval < 0.1\n",
    "    k = group[sig].order -1 \n",
    "    plt.plot(k + add + bar_width/2, group[sig].b.values + group[sig].se_b.values + 0.25, r'*', color='k')\n",
    "#     plt.plot(k + add + bar_width/2, np.repeat(temp.b.max() + 0.25, len(k)), r'*', color='k')\n",
    "\n",
    "grouped2 = temp.groupby('genotype')\n",
    "k = 0\n",
    "col = '#CFCFCF'\n",
    "for name, group in grouped2:\n",
    "    if k % 2 == 0:\n",
    "        xmin = k - bar_width*0.5\n",
    "        xmax = k + bar_width*(len(grouped) + 0.5)\n",
    "        ymin, ymax = plt.gca().get_ylim()\n",
    "        plt.fill_between([xmin, xmax], ymax, color=col)\n",
    "        plt.fill_between([xmin, xmax], ymin, color=col)\n",
    "    k += 1\n",
    "\n",
    "plt.xlim(0, plt.gca().get_xlim()[1] - bar_width)\n",
    "plt.tick_params(axis='y', which='major', labelsize=18)\n",
    "plt.xticks(index + bar_width, temp.genotype.unique(), rotation=45, fontsize=20)\n",
    "pathify(r'\\emph{In Silico} qPCR', '', r'Regression Coefficient, $\\beta$', )\n",
    "plt.legend(loc=(1.02, 0.5), fontsize=15)\n",
    "plt.savefig('../output/pathwaygenes_qPCR.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Absolute Gold Set \n",
    "by Finding the Intersection Between the Double Mutant that is Constitutively Hypoxic and the single mutants that are also hypoxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# gene should be in double constitutive:\n",
    "temp = thomas.beta_filtered['a']\n",
    "temp = temp[temp.qval < 0.1]\n",
    "temp = temp[temp.target_id.isin(hypoxia_genes.target_id)]\n",
    "\n",
    "# should not be in the genes that go up in hif-1 mutants:\n",
    "nothif1 = thomas.beta_filtered['f']\n",
    "nothif1 = nothif1[(nothif1.qval < 0.1) & (nothif1.b > 0)]\n",
    "nothif2 = thomas.beta_filtered['c']\n",
    "nothif2 = nothif2[(nothif2.qval < 0.1) & (nothif2.b > 0)]\n",
    "\n",
    "ind1 = ~temp.target_id.isin(nothif1.target_id)\n",
    "ind2 = ~temp.target_id.isin(nothif2.target_id)\n",
    "temp = temp[(ind1) & (ind2)]\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp['b_sm'] = hypoxia_genes.b\n",
    "temp['qval_avg_sm'] = hypoxia_genes.avg_qval\n",
    "temp['avg_b_sm'] = hypoxia_genes.avg_b\n",
    "\n",
    "gold = temp[temp.b*temp.b_sm > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = (genpy.find(hypoxia_genes, hypoxia_gold.WBIDS, col='ens_gene'))\n",
    "found = hypoxia_genes[ind].ens_gene.unique()\n",
    "sig = len(hypoxia_genes)\n",
    "pval = stats.hypergeom.sf(len(found), len(thomas.beta_filtered['a']), len(hypoxia_gold), sig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hypoxia_genes[ind].ext_gene.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold[gold.target_id.isin(tf_df.target_id)][['ext_gene', 'qval_avg_sm', 'avg_b_sm']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypoxia Positive Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find all the genes in the hypoxia response:\n",
    "ovb = thomas.beta_filtered['b'].copy()\n",
    "ovd = thomas.beta_filtered['d']\n",
    "ove = thomas.beta_filtered['e']\n",
    "ovc = thomas.beta_filtered['c']\n",
    "ova = thomas.beta_filtered['a']\n",
    "\n",
    "ovb['d_qval'] = ovd.qval\n",
    "ovb['e_qval'] = ove.qval\n",
    "ovb['c_qval'] = ovc.qval\n",
    "# ovb['a_qval'] = ova.qval\n",
    "\n",
    "ovb['d_b'] = ovd.b\n",
    "ovb['e_b'] = ove.b\n",
    "ovb['c_b'] = ovc.b\n",
    "# ovb['a_b'] = ova.b\n",
    "\n",
    "# qvalue cutoff\n",
    "ind1 = (ovb.qval < 0.1)\n",
    "# ind2 = (ovb.d_qval < 0.1)\n",
    "ind3 = (ovb.e_qval < 0.1)\n",
    "ind4 = (ovb.c_qval < 0.1)\n",
    "# ind5 = (ovb.a_qval < 0.1)\n",
    "\n",
    "i1 = ind1 & ind2 & ind3 & ind4 #& ind5\n",
    "\n",
    "# make sure they all go in the same direction:\n",
    "# ind5 = (ovb.b*ovb.d_b > 0) & (ovb.b*ovb.e_b > 0) & (ovb.d_b*ovb.e_b >0)\n",
    "# ind6 = (ovb.b*ovb.c_b > 0) & (ovb.c_b*ovb.e_b > 0) & (ovb.d_b*ovb.c_b >0)\n",
    "\n",
    "ind5 =  (ovb.b*ovb.e_b > 0)\n",
    "ind6 = (ovb.b*ovb.c_b > 0) & (ovb.c_b*ovb.e_b > 0)\n",
    "# ind7 = (ovb.b*ovb.a_b > 0) & (ovb.c_b*ovb.a_b > 0) & (ovb.e_b*ovb.a_b > 0)\n",
    "\n",
    "i2 = ind5 & ind6 #& ind7\n",
    "\n",
    "# novel_response = ovb[ind1 & ind2 & ind3 & ind4 & ind5 & ind6].copy()\n",
    "novel_response = ovb[i1 & i2].copy()\n",
    "\n",
    "\n",
    "novel_response['avg_qval'] = (ovb.qval + ovb.d_qval + ovb.e_qval + ovb.c_qval)/4\n",
    "novel_response['avg_b'] = (ovb.b + ovb.d_b + ovb.e_b + ovb.c_b)/4\n",
    "novel_response.sort_values(['avg_qval'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(novel_response.ens_gene.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for a TF that is activated by both egl-9 and hif-1\n",
    "And possibly regulates rhy-1 as a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Figure out how many hits we get and if the pvalue is significant!\n",
    "tfs = {}\n",
    "for sm in thomas.single_mutants:\n",
    "    df = thomas.beta_filtered[sm]\n",
    "    ind = (genpy.find(df, tf_df.target_id, col='target_id'))\n",
    "    found = df[ind & (df.qval < 0.1)]\n",
    "    sig = df[df.qval < 0.1]\n",
    "    pval = stats.hypergeom.sf(len(found), len(df), len(hypoxia_gold), len(sig))\n",
    "    print('genotype: ', sm)\n",
    "    print('found: ', len(found), '      Mean b: {0:.2g}'.format(found.b.mean()))\n",
    "    print('pval: {0:.2g}'.format(pval))\n",
    "    tfs[sm] = found.copy()\n",
    "        \n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_b(x):\n",
    "    vals = tfs['c'][tfs['c'].target_id == x]\n",
    "    if len(vals):\n",
    "        return vals.b.values[0]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "temp = tfs['b']\n",
    "temp['b_c'] = temp.target_id.apply(add_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp[(temp.b_c < 0) & (temp.b < 0)][['ext_gene','b_c','b', 'qval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mxl-3 should be down in the egl, hif double:\n",
    "temp = thomas.beta_filtered['f']\n",
    "temp[(temp.ext_gene == 'mxl-3')][['ext_gene', 'b', 'qval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = thomas.beta_filtered['a']\n",
    "temp[(temp.ext_gene == 'mxl-3')][['ext_gene', 'b', 'qval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = thomas.beta_filtered['e']\n",
    "temp[(temp.ext_gene == 'mxl-3')][['ext_gene', 'b', 'qval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = thomas.beta_filtered['d']\n",
    "temp[(temp.ext_gene == 'mxl-3')][['ext_gene', 'b', 'qval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hypoxia_genes.to_csv('../hypoxia_genes.csv',index=False)\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.embed import file_html\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Use Bokeh chart to make plot\n",
    "hypoxia_genes['logq'] = -np.log(hypoxia_genes.avg_qval)\n",
    "hypoxia_genes['logq'] = hypoxia_genes['logq'].astype(np.float64)\n",
    "hypoxia_genes['avg_b'].astype(np.float64)\n",
    "hypoxia_genes.logq.fillna(700, inplace=True)\n",
    "hypoxia_genes.logq.replace([np.inf], 700, inplace=True)\n",
    "hypoxia_genes.logq.replace([-np.inf], 0, inplace=True)\n",
    "\n",
    "hypoxia_genes.b.replace([np.inf], 6, inplace=True)\n",
    "hypoxia_genes.b.replace([-np.inf], -6, inplace=True)\n",
    "hypoxia_genes.dropna(inplace=True)\n",
    "\n",
    "# What pops up on hover?\n",
    "tooltips = [('ext_gene', '@ext_gene')]\n",
    "\n",
    "# Make the hover tool\n",
    "hover = bokeh.models.HoverTool(tooltips=tooltips)\n",
    "\n",
    "# Create figure\n",
    "p = bokeh.plotting.figure(plot_width=650, \n",
    "                          plot_height=450)\n",
    "p.xgrid.grid_line_color = 'white'\n",
    "p.ygrid.grid_line_color = 'white'\n",
    "p.xaxis.axis_label ='b'\n",
    "p.yaxis.axis_label ='-log(Q)'\n",
    "\n",
    "# Add the hover tool\n",
    "p.add_tools(hover)\n",
    "\n",
    "# Define colors in a dictionary to access them with\n",
    "# the key from the pandas groupby funciton.\n",
    "source1 = bokeh.models.ColumnDataSource(hypoxia_genes[hypoxia_genes.avg_b < 0])\n",
    "source2 = bokeh.models.ColumnDataSource(hypoxia_genes[hypoxia_genes.avg_b > 0])\n",
    "# Specify data source\n",
    "p.circle(x='avg_b', y='logq', size=7, alpha=0.2, source=source1, color='blue')\n",
    "p.circle(x='avg_b', y='logq', size=7, alpha=0.2, source=source2, color='red')\n",
    "p.legend.background_fill_alpha = 0.25\n",
    "p.legend.background_fill_color = 'blanchedalmond'\n",
    "html = file_html(p, CDN, \"my plot\")\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs = np.array([])\n",
    "for key in thomas.beta.keys():\n",
    "    df = thomas.beta_filtered[key]\n",
    "    if len(bs) == 0:\n",
    "        bs = df.b.values\n",
    "        qs = df.qval.values\n",
    "    else:\n",
    "        bs = np.vstack((bs, df.b.values))\n",
    "        qs = np.vstack((qs, df.qval.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b_df = pd.DataFrame(np.transpose(bs), columns = thomas.beta.keys())\n",
    "q_df = pd.DataFrame(np.transpose(qs), columns = thomas.beta.keys())\n",
    "b_df = pd.melt(b_df, var_name='genotype', value_name='b')\n",
    "q_df = pd.melt(q_df, var_name='genotype', value_name='q')\n",
    "b_df['abs b'] = b_df.b.abs()\n",
    "b_df['sorter'] = b_df.genotype.map(sorter)\n",
    "q_df['sorter'] = q_df.genotype.map(sorter)\n",
    "b_df.sort_values('sorter', inplace=True)\n",
    "q_df.sort_values('sorter', inplace=True)\n",
    "b_df['names'] = b_df.genotype.map(genotype_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"names\", y=\"abs b\", data=b_df[q_df.q < 0.1], whis=np.inf, linewidth=1)\n",
    "sns.stripplot('names', 'abs b', data=b_df[q_df.q < 0.1], linewidth=1, jitter=True, alpha=0.05)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(10**-1, 10)\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for genotype in b_df.genotype.unique():\n",
    "    print(genotype, b_df[(b_df.genotype == genotype) & (q_df.q < 10**-1)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding direct targets of *hif-1*, *vhl-1*, *egl-9* and *rhy-1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *hif-1* direct targets\n",
    "Knocking out *hif-1* should decrease levels of hydroxylated and non-hydroxylated *hif-1*\n",
    "\n",
    "Knocking out *vhl-1* should increase levels of both forms. \n",
    "\n",
    "Knocking out *egl-9* or *rhy-1* should decrease the hydroxylated form and increase the non-hydroxylated form. \n",
    "\n",
    "Knocking out *egl-9;hif-1* should decrease levels of hydroxylated and non-hydroxylated *hif-1*\n",
    "\n",
    "Therefore:\n",
    "Overlap *hif-1*, *egl-9* and *rhy-1* mutants with coexpression and find only targets that go DOWN. Next, overlap *vhl-1* with anti-expression. These are the hydroxylated targets of *hif-1* and possibly some other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = thomas.beta['f'].copy() # egl-9;hif-1 double mutant\n",
    "df2 = thomas.beta['c']\n",
    "df3 = thomas.beta['e']\n",
    "df4 = thomas.beta['b']\n",
    "df5 = thomas.beta['a'] # egl-9; vhl-1 double should also decrease hydroxylation of hif\n",
    "df6 = thomas.beta['d']\n",
    "\n",
    "df1['b_c'] = df2.b\n",
    "df1['b_e'] = df3.b\n",
    "df1['b_b'] = df4.b\n",
    "df1['b_a'] = df5.b\n",
    "df1['b_d'] = df6.b\n",
    "\n",
    "\n",
    "df1['q_c'] = df2.qval\n",
    "df1['q_e'] = df3.qval\n",
    "df1['q_b'] = df4.qval\n",
    "df1['q_a'] = df5.qval\n",
    "df1['q_d'] = df6.qval\n",
    "\n",
    "ind = (df1.qval < 0.1) & (df1.q_c < 0.1) & (df1.q_e < 0.1) &\\\n",
    "      (df1.q_b < 0.1) & (df1.q_a < 0.1) & (df1.q_d < 0.1)\n",
    "ind2 = (df1.b < 0) & (df1.b_c < 0) & (df1.b_e < 0) & (df1.b_b < 0) & (df1.b_a < 0)\n",
    "ind3 = (df1.b_d > 0)\n",
    "\n",
    "df1[ind & ind2 & ind3][['ext_gene', 'b_d', 'q_d']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find two genes. . It's possible that we just couldn't measure the hydroxylated *hif-1* targets properly because \n",
    "A less stringent filter would be to just anti-overlap the *vhl-1* with the (*egl-9* and *rhy-1*) mutants and see what comes up. This means we are no longer measuring *hif-1* directly, rather, we are inferring it and hoping that the noise from other stuff that these genes have in common gets drowned out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = (df1.q_e < 0.1) & (df1.q_b < 0.1) & (df1.q_a < 0.1) & (df1.q_d < 0.1) # significant in all relevant depts.\n",
    "ind2 = (df1.b_e < 0) & (df1.b_b < 0) & (df1.b_a < 0) # loss of egl causes hif-OH to go down\n",
    "ind3 = (df1.b_d > 0) # vhl causes hif-OH to go UP\n",
    "hydroxylated_hif = df1[ind & ind2 & ind3]\n",
    "hydroxylated_hif[['ext_gene', 'b_d', 'q_d', 'b_e']].sort_values('q_d').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope! It looks that even our less stringen filter yields quite the small list of targets!\n",
    "\n",
    "Let's find the genes associated with non-hydroxylated hypoxia factor next. \n",
    "\n",
    "Knocking out *hif-1* should decrease levels of hydroxylated and non-hydroxylated *hif-1*\n",
    "\n",
    "Knocking out *vhl-1* should increase levels of both forms. \n",
    "\n",
    "Knocking out *egl-9* or *rhy-1* should decrease the hydroxylated form and increase the non-hydroxylated form. \n",
    "\n",
    "Knocking out *egl-9;hif-1* should decrease levels of hydroxylated and non-hydroxylated *hif-1*\n",
    "\n",
    "Therefore:\n",
    "Overlap *vhl-1*, *egl-9* and *rhy-1* mutants with coexpression and find only targets that go UP. Next, overlap *hif-1* with anti-expression. These are  targets of non-hydroxylated *hif-1* and possibly some other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = (df1.qval < 0.1) & (df1.q_c < 0.1) & (df1.q_e < 0.1) & (df1.q_b < 0.1) & (df1.q_a < 0.1) & (df1.q_d < 0.1)\n",
    "ind2 = (df1.b_e > 0) & (df1.b_b > 0) & (df1.b_a > 0) & (df1.b_d > 0)\n",
    "ind3 = (df1.b < 0) & (df1.b_c < 0)\n",
    "df1[ind & ind2 & ind3][['ext_gene', 'b_e', 'q_e']].sort_values('q_e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we observe only very few genes. Let's try to remove the *hif-1;egl-9* double mutant to increase our sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind = (df1.q_c < 0.1) & (df1.q_e < 0.1) & (df1.q_b < 0.1) & (df1.q_a < 0.1) & (df1.q_d < 0.1)\n",
    "ind2 = (df1.b_e > 0) & (df1.b_b > 0) & (df1.b_a > 0) & (df1.b_d > 0)\n",
    "ind3 = (df1.b_c < 0)\n",
    "df1[ind & ind2 & ind3][['ext_gene', 'b_e', 'q_e']].sort_values('q_e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can definitely say that these are the best candidates for direct control by *hif-1*. However, the list could probably still be larger. \n",
    "\n",
    "Let's weaken the conditions a little bit. Now, we will only require that whatever our candidate genes are, they should not be **significantly upregulated in response to loss of hif-1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind =  (df1.q_e < 0.1) & (df1.q_b < 0.1) & (df1.q_a < 0.1) & (df1.q_d < 0.1)\n",
    "ind2 = (df1.b_e > 0) & (df1.b_b > 0) & (df1.b_a > 0) & (df1.b_d > 0)\n",
    "ind3 = ~((df1.q_c < 0.1) & (df1.b_c > 0)) & ~((df1.qval < 0.1) & (df1.b > 0))\n",
    "hypoxia_direct_targets = df1[ind & ind2 & ind3]\n",
    "print(hypoxia_direct_targets.shape[0])\n",
    "hypoxia_direct_targets[['ext_gene', 'b_e', 'q_e']].sort_values('q_e').head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're talking! We can definitely say that these are the best candidates for direct control by *hif-1*.\n",
    "\n",
    "If we are willing to let go of the difference between hydroxylated and non-hydroxylated *hif-1*, we could remove the *hif-1* filters entirely. However, I think these 167 genes are probably enough for now. Let's take a moment now to verify that this result matches what is known in the literature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tea.enrichment_analysis(hypoxia_direct_targets.ens_gene.unique(), tissue_df, show=True)\n",
    "_ = tea.enrichment_analysis(hypoxia_direct_targets.ens_gene.unique(), phenotype_df, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality control on identified genes:\n",
    "\n",
    "Before we call these *hif-1* targets, we should make sure that at least some known targets are contained in this set. In order to do this, we have curated a list of 20 or so genes that have been published before as *hif-1* targets.\n",
    "\n",
    "That being said though, we need to be aware of 1 major issue with this dataset. \n",
    "\n",
    "*hif-1* and *rhy-1* form an incredibly tight loop. There is a LOT of feedback between *hif-1* and *rhy-1*. Given the kind of logic we are using, we are probably excluding a number of targets as a result. In fact, the logic we have used to develop this list excludes *rhy-1* itself, a known *hif-1* target! I could do better, but not without a lot more lines of code, and it just doesn't seem reasonable to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = hypoxia_direct_targets.ens_gene.isin(hypoxia_gold.WBIDS)\n",
    "found = hypoxia_direct_targets[ind].ens_gene.unique()\n",
    "sig = len(hypoxia_direct_targets)\n",
    "pval = stats.hypergeom.sf(len(found), len(thomas.beta_filtered['a']), len(hypoxia_gold), sig)    \n",
    "\n",
    "if pval < 10**-3:\n",
    "    print('This result is statistically significant \\\n",
    "with a p-value of {0:.2g} using a hypergeometric test. You found {1} gold standard genes!'.format(pval, len(found)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very nice! We are actually sampling from the hif-1 pool! Fantastic! \n",
    "\n",
    "## Identifying *rhy-1* targets\n",
    "\n",
    "Next, let's identify rhy-1 associated genes. We will also insist that rhy-1 genes NOT be associated with hif-1 (they really shouldn't be, the logic between these two sets is mutually exclusive, I think, but it's best to make sure; let's hit stuff with a hammer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind =  (df1.q_e < 0.1) & (df1.q_b < 0.1) & (df1.q_a < 0.1) & (df1.q_c < 0.1)\n",
    "ind2 = (df1.b_e*df1.b_b > 0) & (df1.b_e*df1.b_a > 0) & (df1.b_c*df1.b_e > 0) & (df1.b_c*df1.b_b > 0)\n",
    "ind3 = (~df1.target_id.isin(hypoxia_direct_targets.target_id))\n",
    "rhy1_targets = df1[ind & ind2 & ind3]\n",
    "print(rhy1_targets.shape)\n",
    "rhy1_targets[['ext_gene', 'b_e', 'q_e']].sort_values('q_e').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tea.enrichment_analysis(rhy1_targets.ens_gene.unique(), tissue_df, show=True)\n",
    "_ = tea.enrichment_analysis(rhy1_targets.ens_gene.unique(), phenotype_df, show=False)\n",
    "_[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rhy1_targets[(rhy1_targets.b_e <= rhy1_targets.b_e.min() + 1.5)][['ext_gene','b_e']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying *egl-9* targets\n",
    "OK! We found 'em. Let's find the *egl-9* related genes next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ind =  (df1.q_e < 0.1) & (df1.q_b < 0.1) & (df1.q_a < 0.1) & (df1.q_d > 0.1) & (df1.q_c > 0.1)\n",
    "ind2 = (df1.b_e*df1.b_b > 0) & (df1.b_e*df1.b_a > 0) & (df1.b_b*df1.b_a > 0)\n",
    "#         & (df1.b_c*df1.b_e < 0) & (df1.b_c*df1.b_b < 0)\\\n",
    "#         & (df1.b_b*df1.b_d > 0) & (df1.b_e*df1.b_d > 0)\n",
    "ind3 = True\n",
    "ind4 = (~df1.target_id.isin(hypoxia_direct_targets.target_id))\n",
    "egl_targets = df1[ind & ind2 & ind3  & ind4]\n",
    "print(egl_targets.ens_gene.unique().shape[0])\n",
    "egl_targets[['ext_gene', 'b_b', 'q_b']].sort_values('q_b').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = tea.enrichment_analysis(egl_targets.ens_gene.unique(), tissue_df, show=True)\n",
    "_ = tea.enrichment_analysis(egl_targets.ens_gene.unique(), phenotype_df, show=False)\n",
    "_[0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying *vhl-1* targets\n",
    "Next, let's find the vhl-related genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ind =  (df1.q_a < 0.1) & (df1.q_d < 0.1)\n",
    "ind2 = (df1.b_d > 0) & (df1.b_a > 0)\n",
    "ind4 = (df1.q_e > 0.1) & (df1.q_b > 0.1) & (df1.q_b > 0.1)\n",
    "\n",
    "vhl_targets = df1[ind & ind2 & ind4]\n",
    "print(vhl_targets.shape[0])\n",
    "vhl_targets[['ext_gene', 'b_d', 'q_d', 'b_b', 'b_e']].sort_values('q_d').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = tea.enrichment_analysis(vhl_targets.ens_gene.unique(), tissue_df, show=True)\n",
    "_ = tea.enrichment_analysis(vhl_targets.ens_gene.unique(), phenotype_df, show=False)\n",
    "_[0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying New Biology - understanding the role of *rhy-1* and *egl-9* in the *hif-1* dependent response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = (df1.q_c < 0.1) & (df1.q_e < 0.1) &\\\n",
    "      (df1.q_b < 0.1) & (df1.q_a < 0.1) & (df1.q_d < 0.1)\n",
    "y = df1[ind][['b_e', 'b_b', 'b_d', 'b_c', 'b', 'b_a']]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_down = y[y<0].dropna().index\n",
    "all_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_down = df1[df1.index.isin(y[y<0].index)][['ext_gene', 'ens_gene', 'b_e', 'b_b', 'b_d', 'b_c', 'b_a',\n",
    "                               'q_e', 'q_b',\n",
    "                               'q_d', 'q_c', 'q_a']].sort_values('q_a')\n",
    "all_down.to_csv('../output/all_down.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_up = y[y>0].dropna().index\n",
    "print(all_up.shape)\n",
    "all_up = df1[df1.index.isin(all_up)][['ext_gene', 'ens_gene', 'b_e', 'b_b', 'b_d', 'b_c', 'b_a',\n",
    "                               'q_e', 'q_b',\n",
    "                               'q_d', 'q_c', 'q_a']].sort_values('q_a')\n",
    "all_up.to_csv('../output/all_up.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = (df1.q_c < 0.1) & (df1.q_e < 0.1) &\\\n",
    "      (df1.q_b < 0.1) & (df1.q_d < 0.1)\n",
    "y = df1[ind][['b_e', 'b_b', 'b_d', 'b_c']]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = (df1.q_c < 0.1) & (df1.q_e < 0.1) &\\\n",
    "      (df1.q_b < 0.1) & (df1.q_d < 0.1) & (df1.qval < 0.1)\n",
    "y = df1[ind][['b_e', 'b_b', 'b_d', 'b_c']]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y.b_e, y.b_a, 'ro')\n",
    "plt.plot(y.b_d, y.b_a, 'bo')\n",
    "x = np.linspace(plt.gca().get_xlim()[0], plt.gca().get_xlim()[1], plt.gca().get_xlim()[1] - plt.gca().get_xlim()[0])\n",
    "plt.plot(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y.b_e, y.b_a - y.b_e, 'ro')\n",
    "plt.plot(y.b_d, y.b_a - y.b_d, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y.b_c, y.b - y.b_c, 'ro')\n",
    "plt.plot(y.b_e, y.b - y.b_e, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y.b_c, y.b, 'ro')\n",
    "plt.plot(y.b_e, y.b, 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "697px",
   "left": "0px",
   "right": "1228px",
   "top": "106px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
